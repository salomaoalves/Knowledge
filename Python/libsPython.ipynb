{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jLymYqdxi3bt"},"outputs":[],"source":["# Download Libs - use !pip in jupyter\n","pip install <lib_name>          #one lib\n","pip install -r requirements.txt #group of libs"]},{"cell_type":"markdown","metadata":{"id":"r3UNZnXQnwcO"},"source":["General --> Random, Datetime, RegEx\n","\n","Graphs --> NetworkX, iGraph\n","\n","Data --> Numpy, Pandas, Profiling\n","\n","Better Performace --> Numba, Dask, Vaex\n","\n","Web -> Flask, Django, Dash\n","\n","Others --> AstroML"]},{"cell_type":"markdown","metadata":{"id":"VswdO1cPn75A"},"source":["# **General**"]},{"cell_type":"markdown","metadata":{"id":"FndVPxhflLst"},"source":["## *Random*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i0t5qW4SlO9o"},"outputs":[],"source":["import random\n","\n","random.seed(numbInt)                               #initialize the random number generator (to repeat experiments)\n","random.choice(sequence)                            #returns a element from a sequence (string/list/range/tuple/..)\n","random.sample(seq,kInt)                            #returns a sample of size k from a sequence\n","random.shuffle(seq,func=random())                  #shuffles a sequence - changes the original seq\n","random.randrange(startInt=0,stopInt,stepInt=1)     #returns a random number between the given range\n","random.random()                                    #returns a float number between 0 and 1\n","random.normalvariate()                             #returns a float number based on the normal dist (have for others)\n","\n","# https://www.w3schools.com/python/module_random.asp #"]},{"cell_type":"markdown","metadata":{"id":"zyj1oQwhw33A"},"source":["## *Datetime*"]},{"cell_type":"markdown","metadata":{"id":"inNr7h0Ul1Jp"},"source":["To creat a date/time/datetime format:\n","\n","*   %Y -> year (1999)\n","*   %y -> year (99)\n","*   %b -> month (Jan..Dec)\n","*   %B -> month (January..December)\n","*   %m -> month (01..12)\n","*   %d -> day (01..31)\n","*   %A -> week day (Sunday..Monday)\n","*   %H -> hour (00..23)\n","*   %I -> hour (01..12)\n","*   %p -> hour (am|pm)\n","*   %M -> minute (00..59)\n","*   %s|S -> second (00..59)\n","*   %Z -> time zone name (UTC)\n","*   %j -> day of the yaer (001..366)\n","\n","Can use / and - to separate the date and : to separate the time."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1025,"status":"ok","timestamp":1646179909973,"user":{"displayName":"Salomao Alves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01229308303208121589"},"user_tz":180},"id":"AtspY7aXumrf","outputId":"b5b634c9-8b36-4ad5-942e-dd570b153964"},"outputs":[{"data":{"text/plain":["datetime.datetime(2022, 3, 2, 0, 11, 48, 777087)"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["from datetime import date, time, datetime, timedelta\n","from dateutil.relativedelta import relativedelta\n","\n","date.today()      #get current date\n","datetime.now()    #get current datetime"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1646179918484,"user":{"displayName":"Salomao Alves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01229308303208121589"},"user_tz":180},"id":"z0Cfe5wH9fDY","outputId":"c474355e-425c-4549-d7cc-571b35507065"},"outputs":[{"data":{"text/plain":["datetime.datetime(2021, 1, 1, 14, 15, 25)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["dateObj = date(year=2021, month=1, day=10)         #create a date object\n","timeObj = time(hour=14, minute=15, second=14)      #create a time object\n","dttmObj = datetime(year=2021, month=1, day=1,      #create a datetime object\n","                   hour=14, minute=15, second=25)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v48vgVbQALIf"},"outputs":[],"source":["timeObj.hour #or: .minute - .second - .microsecond\n","dateObj.year #or: .month - .day\n","dateObj.weekday()     #exclusive - 0/Monday to 6/Sunday\n","dateObj.isocalendar() #exclusive - return: (year, week of year, weekday)\n","dttmObj.timestamp() #datetime have the same attr as date and time obj"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VBoIpnHQ-Frn"},"outputs":[],"source":["date.fromisoformat(\"2021-01-10\")         #convert from string iso to Date\n","datetime.fromtimestamp(1610030000)       #convert from timestamp to Datetime\n","datetime.strptime(date_str, date_format) #convert from string to Datetime\n","dttmObj.strftime(datetime_format)    #convert from Datetime to Python String"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"isD3Khwr-vRP"},"outputs":[],"source":["datetime.today() + timedelta(days=1) #add(+)/subtract(-) some period of time\n","dateObj - date(2020,1,10)            #subtract date/time/datetime (both obj need to be the same)\n","timedelta()                          #creates a period of time; can use 'weeks=', 'days=', 'hours=', 'minutes=' and 'seconds='\n","relativedelta()                      #creates a period of time; can use 'years=' and 'months='\n","timedelta().total_seconds()          #the period of time in seconds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHI-oJdnBOG9"},"outputs":[],"source":["import pytz     #to manipulate time zones\n","\n","tz = pytz.timezone(TimeZone)     #creat a timezone object\n","datetime.now(TimeZone)           #return the current datetime using the time zone\n","pytz.all_timezones               #list all time zones"]},{"cell_type":"markdown","metadata":{"id":"EQifVk7U1uE6"},"source":["## *RegEx*"]},{"cell_type":"markdown","metadata":{"id":"TCCa9wAO18At"},"source":["To creat a pattern:\n","\n","* () -> capture and group\n","* [] -> a set o characters -> [a-z]\n","* {} -> specified numb of occur -> he.{2}o\n","* \\ -> escape characters -> \\[\n","* . -> any character -> he..o\n","* ^ -> start with -> ^Hello\n","* \\$ -> ends with -> end$\n","* \\* -> 0 or more occur -> he.*o\n","* \\+ -> 1 or more occur -> he.+o\n","* ? -> 0 or 1 occur -> he.?o\n","* \\| -> either or -> false|true\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MyTckOP31tID"},"outputs":[],"source":["import re\n","re.findall(pattern, txt)        #return a list of all matches in the order they're found\n","re.search(pattern, txt)         #if founded, return a Match Obj of ther first occur, if not founded, return None\n","re.split(pattern, txt)          #returns a list with the string split in each point, can control the numb of split with maxsplit param\n","re.sub(pattern, replace, txt)   #replace every pattern by it replace, can control de numb of replacement with count param"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQkhK8ii4vQz"},"outputs":[],"source":["#Match Object\n","matchObj.span()            #returns the position (start and end) of the first match occur\n","matchObj.string            #returns the string passed into the function\n","matchObj.group()           #returns the part of the string where there was a match"]},{"cell_type":"markdown","metadata":{"id":"mXqvmKjtv0Dg"},"source":["# **Graphs**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4167,"status":"ok","timestamp":1663510385002,"user":{"displayName":"Salomao Alves","userId":"01229308303208121589"},"user_tz":180},"id":"bOlvjy888dPf","outputId":"eff81439-ade0-408d-df88-b2ecfea0f244"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (2.6.3)\n"]}],"source":["!pip install networkx\n","#!pip install igraph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3qA0z1rqvWHT"},"outputs":[],"source":["#from igraph import Graph, plot\n","import networkx as nx"]},{"cell_type":"markdown","metadata":{"id":"WQqTKAzobGET"},"source":["## *NetworkX*"]},{"cell_type":"markdown","metadata":{"id":"eTf--iS2q1Z2"},"source":["Uses a “dictionary of dictionaries of dictionaries” as the basic network data structure. This allows fast lookup with reasonable storage for large sparse networks.\n","\n","A graph: `(A) -- (B) -- (C)`, will be stored as: `{'A': {'B': {}}, 'B': {'A': {}, 'C': {}}, 'C': {'B': {}}}`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTK7_jFCH-hL"},"outputs":[],"source":["# Variables - each tuple is a edge\n","G = nx.Graph()\n","numb_nodes = 10\n","n1, n2 = 'node1', 'node2'\n","list_of_node = ['a', 'b']\n","\n","list_of_tuple = [('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd')]\n","list_of_tuple_weighted = [('a', 'b', 5.0), ('b', 'c', 3.0), ('a', 'c', 1.0), ('c', 'd', 7.3)]"]},{"cell_type":"markdown","metadata":{"id":"tU0f7iSwbxoT"},"source":["### Graph creation"]},{"cell_type":"markdown","metadata":{"id":"mgCT-hPUqj5G"},"source":["**Graph:** this class implements an undirected graph. It ignores multiple edges between two nodes. It does allow self-loop edges between a node and itself.\n","\n","**DiGraph:** directed graphs, that is, graphs with directed edges. Provides operations common to directed graphs, (a subclass of Graph).\n","\n","**MultiGraph:** a flexible graph class that allows multiple undirected edges between pairs of nodes *- parallel edges allowed*. The additional flexibility leads to some degradation in performance, though usually not significant.\n","\n","**MultiDiGraph:** a directed version of a MultiGraph."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m4qeswMDbFFF"},"outputs":[],"source":["G = nx.Graph()\n","G = nx.DiGraph()\n","G = nx.MultiGraph()\n","G = nx.MultiDiGraph()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZanFr7l5QVbK"},"outputs":[],"source":["G = nx.empty_graph(numb_nodes, create_using=nx.Graph)     #empty graph\n","G = nx.complete_graph(numb_nodes, create_using=nx.Graph)  #complete K_n graph\n","G = nx.cycle_graph(numb_nodes, create_using=nx.Graph)     #cycle C_n graph of cyclically connected nodes"]},{"cell_type":"markdown","metadata":{"id":"1XMeHRRxHDFP"},"source":["### Nodes n Edges Operations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcXQrnoIHm1p"},"outputs":[],"source":["G.graph #return the graph - dict format\n","G.nodes #return all nodes - dict format - can be index\n","G.edges #return all edges - tuple format - can be index\n","#for all, with '.data()' can see the attr - like G.nodes.data()\n","#there is also, '.items()', '.copy()', '.keys/values()'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3HeqGxHoHCLC"},"outputs":[],"source":["G.add_node(n1)                                      #add new node\n","G.add_nodes_from(list_of_node)                      #add a list of nodes\n","\n","G.add_edge(n1, n2, weight=0.9)                      #add a new edge with weight\n","G.add_edges_from(list_of_tuple)                     #add a list of edges\n","G.add_weighted_edges_from(list_of_tuple_weighted)   #add a list of edges w/ weight"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XTIk9GgzLJqR"},"outputs":[],"source":["G.add_node(n1, attr='')                   #add attr into this node\n","G.add_nodes_from(list_of_node, attr='')   #add attr into all nodes\n","G.nodes[n1]['attr'] = ''                  #add attr into this node\n","del G.nodes[n1]['attr']                   #delete attr of this node\n","\n","G.add_edge(n1, n2, attr='')               #add attr into this edge\n","G.add_edges_from(list_of_tuple, attr='')  #add attr into all edges\n","G.edges[n1, n2]['attr'] = ''              #add attr into this edge\n","G[n1][n2]['attr'] = ''                    #add attr into this edge\n","list_of_tuple = [('a','b',{\"attr\":''}), ('b','c',{\"attr\":''})] #another way"]},{"cell_type":"markdown","metadata":{"id":"ySVBS9akM3yF"},"source":["### Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":333,"status":"ok","timestamp":1663416448891,"user":{"displayName":"Salomao Alves","userId":"01229308303208121589"},"user_tz":180},"id":"Qb-r_WRmM39-","outputId":"efda9168-25d6-44de-8504-dd0859ed925e"},"outputs":[{"data":{"text/plain":["[('n1', 'n1'), ('n', 'n')]"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["G.adj   #adj vertex\n","graph.predecessors(n1)\n","graph.successors(n1)\n","graph.in_degree(n1)\n","graph.out_degree(n1)\n","\n","list(nx.selfloop_edges(G, keys=True, data=True))  #a list of self loops"]},{"cell_type":"markdown","metadata":{"id":"_IykK_iMtOAG"},"source":["### Algorithms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zeMJ0pGktP5Y"},"outputs":[],"source":["#Short Path\n","nx.shortest_path(G, source=None, target=None) #if None, compute all possible nodes\n","nx.dijkstra_path(G, source, target, weight='weight')\n","nx.bellman_ford_path(G, source, target, weight='weight')\n","nx.astar_path(G, source, target, heuristic=None, weight='weight')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VO4u508XuGCC"},"outputs":[],"source":["nx.diameter(G, e=None, usebounds=False)\n","nx.radius(G, e=None, usebounds=False)\n","\n","nx.isolates(G)\n","nx.number_of_isolates(G)\n","\n","nx.core_number(G)\n","nx.k_core(G, k=None, core_number=None)\n","nx.k_shell(G, k=None, core_number=None)\n","nx.k_corona(G, k, core_number=None)"]},{"cell_type":"markdown","metadata":{"id":"4mhyMiqLbGx6"},"source":["## *iGraph*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nl_mGa_DxCeA"},"outputs":[],"source":["# Creates a graph - edges: list of tuple, where each element is a vert\n"," #                  directed: bool, if is a directed or undirected graph\n","graph = Graph(edges=[(0,1),(1,2),(1,1),(2,3),(0,3),(3,0)], directed=True)\n","graph['name'] = 'Graph name'\n","\n","graph.add_vertex(n=4) #add n new vertices\n","graph.add_edges([(0,4)]) #add new edges\n","\n","matAdj = graph.get_adjacency() #adjacency matrix, can use [ to slice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vuXsvggf01Yv"},"outputs":[],"source":["# Properties: when .vs is about vertices, when .es is about edges\n"," # Can create others properties, because a dict is generated\n"," # The ones below are recognized\n","graph.vs['label'] = ['a','b','c','d'] #set verts labels - show in the plot\n","graph.vs['type'] = ['a','b','c','d'] #set verts types\n","graph.vs['name'] = ['a','b','c','d'] #set verts names - used to show the edges\n","graph.es['label'] = ['a','b','c','d','e','f'] #set edges labels - show in the plot\n","graph.es['weight'] = [188,25,38,40,1,22] #set edges weight\n","\n","# Interate throw the edges and vertices\n","for e, v in graph.es, graph.vs:\n","  pass #can set a prop for a especific vert/edge\n","\n","print(graph) #to see attr/proper and edges"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gB6vUAa0DOHM"},"outputs":[],"source":["# Find Small Path\n"," # 0 and 7: interger - vertices position\n"," # output: vpath | epath - from who the index in the result is reference to\n"," # result: a list of vert ('vpath') or edges ('epath') indexes\n","path = graph.get_shortest_paths(0,7,output='')\n","\n","# Create Clusters\n","cluster = graph.clusters()\n","cluster.membership #see which cluster each vert belongs\n","hierarc = graph.community_edge_betweenness() #creates hierarchical grouping\n","hierarc.optimal_count #ideal number of clusters\n","hierarc.as_clustering #ideal hierarchical grouping\n","\n","# Create Cliques\n","cli = graph.cliques(min=2) #min: of elements per click"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iR4wKqd527-z"},"outputs":[],"source":["# Plots - below some parameters\n"," # vertex_size   =  list or graph.prop     -  change the vert size\n"," # vertex_shape  =  'square'               -  change the vert shape\n"," # vertex_color  =  ['blue','green','red'] -  change the vert colors\n"," # edge_width    =  list or graph.prop     -  change the edge width\n"," # edge_curved   =  Number                 -  put curvature on edges\n"," # edge_label    =  list or graph.prop     -  set the edges labels\n","\n","graph = Graph(edges=[(0,1),(2,3),(0,2),(0,3)],directed=True)\n","graph.vs['label'] = ['Fernando','Pedro','Jose','Antonio']\n","graph.vs['peso'] = [40,30,30,25]\n","graph.es['TipoAmizade'] = ['Amigo','Inimigo','Inimigo','Amigo']\n","graph.es['weight'] = [1,2,1,3]\n","\n","plot(graph,bbox=(300,300),vertex_size=graph.vs['peso'])\n","plot(graph,bbox=(300,300),edge_width=graph.es['weight'])\n","plot(graph,bbox=(300,300),vertex_color=['blue','green','red','yellow'])\n","plot(graph,bbox=(300,300),edge_curved=0.4)\n","plot(graph,bbox=(300,300),vertex_shape='square')\n","plot(graph,bbox=(300,300),edge_label=graph.es['weight'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gtbpF1_v03Tu"},"outputs":[],"source":["# Metrics\n","\n","graph.degree(mode='all') #vert's degree - in and out\n","graph.degree(mode='out') #emission degree - just out\n","graph.degree(mode='in')  #reception degree - just in\n","\n","graph.diameter(directed=True) #return the graph's diameter\n","graph.getdiameter() #return the diameter from the vert\n","graph.neighborhood() #return the vert's neighborhood"]},{"cell_type":"markdown","metadata":{"id":"OLw3ePoirT-Q"},"source":["# **Data**"]},{"cell_type":"markdown","metadata":{"id":"HuNxhh38bwFR"},"source":["## [*NumPy*](https://numpy.org/doc/stable/reference/arrays.html)\n","\n","It has objects called arrays, that are multidimensional *- ndarray*, and routines to process them."]},{"cell_type":"markdown","metadata":{"id":"6RK3HiPZVHSZ"},"source":["### Array Creation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7gqqF8-ngZ0"},"outputs":[],"source":["## dtype: optional - desired data-type for the array\n","## shape: tuple :: (numb of rows, numb of cols)\n","## start: optional - integer or real :: start of interval\n","## end: integer or real :: end of interval\n","## step: optional - integer or real :: spacing between values\n","## num: number of samples to generate\n","## N: int :: numb of rows (in .vander is of cols and optional)\n","## M: optional - int :: numb of cols - if None, use N\n","## k: optional - int :: diagonal in question - 0 for the main, > for diag above main one, < for diag below main one\n","## v: array-like :: if is a 2D array return a copy of its k-th diag, if is 1D array return a 2D array with v on the k-th diag\n","## x: array-like :: 1D input array\n","\n","d1array = np.array([2, 3, 4], dtype)\n","d2array = np.array([(1.5, 2, 3), (4, 5, 6)], dtype)\n","d3array = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]], dtype)\n","\n","np.zeros(shape, dtype)\n","np.ones(shape, dtype)\n","np.empty(shape, dtype)\n","\n","# 1-D Arrays\n","np.arange(start, end, step, dtype) #return evenly spaced values within a given interval\n","np.linspace(start, end, num=50)    #return evenly spaced numbers over a specified interval - size of num\n","\n","# 2-D Arrays\n","np.eye(N, M, k, dtype) #2D Identity Matrix\n","np.diag(v, k)          #extract a diagonal or construct a diagonal array\n","np.vander(x, N)        #generate a Vandermonde matrix"]},{"cell_type":"markdown","metadata":{"id":"Ml6uxSvuVLhm"},"source":["### Attributes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b7GQE3-kbtVD"},"outputs":[],"source":["ndarray.ndim     #the number of axes (dimensions) of the array\n","ndarray.shape    #the dimensions of the array === `np.shape(ndarray)`\n","ndarray.size     #the total number of elements of the array\n","ndarray.dtype    #an object describing the type of the elements in the array\n","ndarray.itemsize #the size in bytes of each element of the array\n","ndarray.data     #the buffer containing the actual elements of the array"]},{"cell_type":"markdown","metadata":{"id":"Rh-nd5jMVRtE"},"source":["### Slacing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YnwFPUYPt6X4"},"outputs":[],"source":["# use the same one used in Python List\n","\n","## 1D Array\n","d1array[0]     #fisrt element - position 1\n","d1array[-1]    #last element (valid above)\n","d1array[1:3]   #get a range between [1:3[\n","d1array[1:3:2] #the above with step - 2 in 2\n","d1array[:]     #everything\n","\n","## 2D Array\n","d2array[IndRow][IndCol] # or `d2array[IndRow,IndCol]`\n","d2array[1:2,:]\n","d2array[:,np.array([3, -3, 1])] #a ndarray of the elements index or boolean\n","\n","## 3D Array\n","d3array[IndDim1][IndDim2][IndDim3] # or `d2array[IndDim1,IndDim2,IndDim3]`\n","d3array[1:2,:,-1]\n","\n","## Ellipsis - expands to the number of : objects needed\n","d3array[..., 0] === d3array[:, :, 0]"]},{"cell_type":"markdown","metadata":{"id":"3FSZgB1ZVVrO"},"source":["### Operations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MkpYvtmea4yP"},"outputs":[],"source":["d1array + d1array #element-wise - can use a scalar too\n","## the same is valid for (sub,-), (mul,*), (div,/),\n","##   (floordiv,//), (mod,%), (pow,**)"]},{"cell_type":"markdown","metadata":{"id":"QOW6EMaBVeae"},"source":["### Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVB4PxuafQAp"},"outputs":[],"source":["##array: array-like :: input array\n","##casting: {‘no’: dtype not cast, ‘equiv’: only byt-order changes allowed,\n","           #‘safe’: only safe cast, ‘same_kind’: only safe casts or within a kind are allowed,\n","           #‘unsafe’: any conversion may be done\n","##axis: optional - int :: the axis along will be joined (0 rows; 1 cols)\n","\n","#make a copy\n","np.copyto(dst, #ndarray :: array into which values are copied\n","          src, #array-like :: array from which values are copied\n","          casting='same_kind' #optional\n","          )\n","\n","\n","#reshape a ndarray - can use `ndarray.reshape(newshape)`\n","np.reshape(array, newshape, #int or tuple of int :: should be compatible with the original one\n","                              #each int is the numb of that dimension; one can be -1,\n","                              #so the value is inferred from the array length and remaining dimensions\n","           )\n","\n","\n","np.transpose(array) #make the tranpose - can use `ndarray.T`\n","np.squeeze(array)   #remove axes of length one\n","\n","\n","#join a sequence of array along an existing axis\n","np.concatenate((a1,a2,...), #seq of array-like :: arrays input\n","               axis=0, out, #optional - ndarray :: if provided, the destination to place the result\n","               dtype, casting)\n","\n","#split an array into multiple sub-arrays as views into ary - can use `np.array_split(array, axis=0, indices_or_sections)`\n","np.split(array, axis=0,\n","         indices_or_sections #int or 1D array :: array will be divide in N equal parts, if is a 1D array, the elements are the position to return\n","         )\n","\n","#repeat elements of an array\n","np.reapeat(array, axis, #axis along to reapeat - by default, use the flattened input array, and return a flat output array\n","           repeats      #int or array of ints :: numb of repetitions for each element\n","           )\n","\n","#insert values along the given axis before the given indices\n","np.insert(array, obj, #int, slice or seq of ints :: defines the index before which values is inserted\n","          values,     #array-like :: values to insert into array\n","          axis=None   #if None then array is flattened first\n","          )\n","\n","#return a new array with sub-arrays along an axis deleted\n","np.delete(arr, obj, #slice, int or seq of ints :: indices to remove along the axis\n","          axis=None #if None then both array is flattened first\n","          )\n","\n","#append values to the end of an array\n","np.append(array, values, #array-like :: values to be appended\n","          axis=None      #if None then both array is flattened first\n","          )\n","\n","#trim the leading and/or trailing zeros\n","np.trim_zeros(filt, #1D array or sequence - input\n","              trim  #optional - str :: 'f' for trim from front, 'b' for trim from back and 'fb' for both\n","              )\n","\n","#find the unique elements of an array\n","np.unique(array, return_index=False, #optional - bool :: if True return the indeces of array\n","          return_counts=False,       #optional - bool :: if True return the numb of times each unique item appears\n","          axis=None, equal_nan=True  #optional - bool :: if True, collapses multple NaN values into one\n","          )\n","\n","np.flip(array, axis=None) #reverse the order of elements in an array along the given axis"]},{"cell_type":"markdown","metadata":{"id":"XVB9xa7CVbku"},"source":["### String Operations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5L8V0-zQqFTv"},"outputs":[],"source":["# String Operations - for more: https://numpy.org/doc/stable/reference/routines.char.html#\n","\n","np.capitalize(array) #return a copy of a with only the first character of each element capitalized\n","np.upper(array)      #return an array with the elements converted to uppercase\n","np.lower(array)      #return an array with the elements converted to lowercase"]},{"cell_type":"markdown","metadata":{"id":"qfc6ANMLc-c1"},"source":["## [*Pandas*](https://pandas.pydata.org/docs/reference/)\n","\n","\n","It has functions for analyzing, cleaning, exploring, and manipulating data."]},{"cell_type":"markdown","metadata":{"id":"dYrEu6hv307w"},"source":["### Read/Write data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gA29XbISqTAf"},"outputs":[],"source":["## CSV Files\n","\n","df = pd.read_csv(filepath_or_buffer, sep=',', header='infer', #if 'infer'/0 get the first row OR a list of int OR int\n","                 names=['Option'], #array-like of column names to use - header=0 will override\n","                 index_col,        #optional - int, str or sequence of int/str :: to use as the row labels\n","                 usecols,          #optional - list of int/str :: return a subset of the columns, can be the col index or name\n","                 dtype,            #optional - type name or dict of column/dataType (a dict w/ col as key and col type as value)\n","                 skiprows,         #optional - list-like, int or callable :: will skip a list of index OR numbers of lines from start\n","                 skipfooter=0,     #number of lines at bottom of file to skip\n","                 nrows=None,       #number of rows of file to read\n","                 parse_dates,      #optional - list of str :: the col names that should be treat as TimeStamp - use this format: \"%Y-%d-%m %H:%M:%S\"\n","                 date_parser,      #optional - callable func :: aux func like `lambda x: datetime.strptime(x, \"%Y-%d-%m %H:%M:%S\")`\n","                 encoding,         #optional - str :: encoding to use for UTF when reading/writing, like 'ascii' 'cp860' 'utf_32' 'utf_16' 'utf_7' 'utf_8'\n","                 )\n","pd.DataFrame.to_csv(path_or_buf=None, sep=',', na_rep='', float_format=None,\n","                    columns,     #optional - sequence of columns to write\n","                    header=True, #bool or list of str :: write out the column names\n","                    index=True,  #write row names - the index\n","                    encoding)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m7eo0Ezpu4zR"},"outputs":[],"source":["## Excel\n","\n","df = pd.read_excel(io_path,      #file path\n","                   sheet_name=0, #str, int, list, None :: get the sheet name OR index OR a list of index/name OR all worksheets\n","                   header=0,     #int, list of int, None :: row (0-indexed) to use for col labels OR a list of integers OR no header\n","                   names=None,   #array-like, list of col names to use - 'header=None'\n","                   index_col=None, usecols=None, squeeze=None, dtype=None, skiprows=None, nrows=None, skipfooter=0)\n","\n","#to write multiple sheets it is necessary to create an ExcelWriter object and insert each sheet\n","pd.DataFrame.to_excel(excel_writer_path, sheet_name='', columns=None, header=True, index=True,\n","                      na_rep='',         #missing data representation\n","                      float_format=None, #format string for floating point numbers - ex. \"%.2f\"\n","                      )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7i9_A6lzu7qU"},"outputs":[],"source":["## JSON\n","# orient: indication of expected json string format\n","df = pd.read_json(path_or_buf, orient)    #convert a json string to df\n","pd.DataFrame.to_json(path_or_buf, orient) #convert a df to json string\n","\n","## XML\n","df = pd.read_xml(path_or_buffer,   #file path\n","                 xpath='./*',      #XPath to parse required set of nodes\n","                 namespaces=None,  #the namespaces defined in XML document as dicts with key bey namespace prefix and value the uri\n","                 elems_only,       #optional, bool, parse only the child elements\n","                 attrs_only,       #optional, bool, parse only the attribute at the specified xpath\n","                 names=None,       #col names for dataframe of parsed xml data\n","                 encoding='utf-8', #optional - str :: encoding to use for UTF when reading/writing, like 'ascii' 'cp860' 'utf_32' 'utf_16' 'utf_7' 'utf_8'\n","                 dtype=None        #optional - type name or dict of column/dataType (a dict w/ col as key and col type as value)\n","                 )\n","pd.DataFrame.to_xml(path_or_buffer,   #file path\n","                    index=True,       #include or not the index\n","                    root_name='data', #the root element name\n","                    row_name='row',   #the name of the row element\n","                    na_rep,           #optional - str :: missing data representation\n","                    attr_cols,        #optional - list-like or list of col to write as attributes in row element\n","                    elem_cols,        #optional - list-like or list of col to write as children in row element\n","                    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXpZCJphdAiM"},"outputs":[],"source":["## Pickle\n","df = pd.read_pickle(filepath_or_buffer, compression='infer', storage_options=None)   #load pickled pd object from file\n","pd.DataFrame.to_pickle(path, compression='infer', protocol=5, storage_options=None)  #pickle object to file\n","\n","## Fixed-width formatted lines\n","df = pd.read_fwf(filepath_or_buffer, colspecs='infer', widths=None, infer_nrows=100) #read a table of fixed-width formatted lines into DataFrame\n","\n","## Latex\n","pd.DataFrame.to_latex(buf=None,          #file path\n","                      columns=None,      #the subset of columns to write - write all by default\n","                      col_space=None,    #the minimum width of each column\n","                      header=True,       #bool or list of str :: write out the column names\n","                      index=True,        #bool :: write row names (index)\n","                      na_rep='NaN',      #missing data repesentation\n","                      float_format=None  #format string for floating point numbers - ex. \"%.2f\"\n","                      )\n","\n","## Parquet\n","df = pd.read_parquet(path,          #file path\n","                     engine='auto', #parquet library to use\n","                     columns=None,  #list of columns to be read\n","                     )\n","pd.DataFrame.to_parquet(path=None, engine='auto', compression='snappy')\n"]},{"cell_type":"markdown","metadata":{"id":"pT-9EqwN5DzD"},"source":["### Functions"]},{"cell_type":"markdown","metadata":{"id":"bBygxEY9KWLz"},"source":["#### Data Manipulation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7uPHSQib5Fqf"},"outputs":[],"source":["\n","#compute a simple cross tabulation of two (or more) factors\n","pd.crosstab(index, columns,         #array-like, series, list of arrays/series :: values to group by in the rows/cols\n","            values=None,            #optional, array-like :: to agg according to the factor - requires aggfunc\n","      rownames=None, colnames=None, #sequence :: if passed, must match the row/col passed\n","            aggfunc=None,           #function to agg - requires values\n","            margins=False,          #bool :: add roq/col margins (subtotais)\n","            margins_name='All')\n","\n","#bin values into discrete intervals - segment and sort data values into bins\n","pd.cut(x, #array-like :: input to be binned\n","       bins, #int, sequence of scalars, IntervalIndex :: defines the range of bins or the bin edges or the exact bins to be used\n","       right=True,\n","       labels=None, #array or False :: specifies the labels for the bins\n","       ordered=True #sort or not\n","       )\n","\n","#quantile-based discretization function\n","pd.qcut(x, q, #int, list-like of float :: number of quantiles or array of quantiles\n","        labels=None)\n","\n","#concatenate pandas objects along a particular axis\n","pd.concat(objs,               #sequence or mapping of Serie/DataFrame objects\n","          axis=0,             #axis to concatenate - 0/index  1/columns\n","          join='outer',       #str :: join type to use\n","          ignore_index=False, #bool :: if True, ignore the index values along the axis\n","          )\n","\n","#convert categorical variable into dummy/indicator variables\n","pd.get_dummies(data, #array-like, Series, DataFrama :: data to get dummy indicators\n","               prefix=None, #str, list/dict of str :: str to append df cols names\n","               prefix_sep='_', #str :: if appending prefix, separator/delimiter to use\n","               dummy_na=False, #bool :: add a col to indicate NaNs\n","               )\n","\n","#create a categorical DataFrame from a DataFrame of dummy variables\n","pd.from_dummies(data, sep=None, #str :: separator/delimiter used in the dummy var\n","                )\n","\n","#return unique values based on a hash table\n","pd.unique(values #1d array-like\n","          )"]},{"cell_type":"markdown","metadata":{"id":"0JBezPY9KbXn"},"source":["#### Missing data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WGqvUH0wIoaF"},"outputs":[],"source":["#obj: scalar or array-like :: obj to check\n","pd.isna(obj)    #detect missing values for an array-like object\n","pd.isnull(obj)  #detect missing values for an array-like object\n","pd.notna(obj)   #detect non-missing values for an array-like object\n","pd.notnull(obj) #detect non-missing values for an array-like object"]},{"cell_type":"markdown","metadata":{"id":"rvmaRrcZKfiY"},"source":["#### Type transformation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_K3xbm2KmQy"},"outputs":[],"source":["\n","pd.to_numeric(arg #scalar, list, tuple, 1-d array, Series :: to be converted\n","              ) #convert argument to a numeric type\n","\n","pd.to_datetime(arg, #int, float, str, datetime, list, tuple, 1-d array, Series, DataFrame/dict-like :: obj to convert\n","               utc=None, #bool :: control timezone-related parsing, localization and conversion, if True shows\n","               format=None, #str :: date format, like \"%d/%m/%Y\"\n","               ) #convert argument to datetime\n","\n","pd.to_timedelta(arg, #str, timedelta, list-like, Series :: to be converted\n","                ) #convert argument to timedelta\n","\n","pd.date_range(start=None, end=None, #optinal - str, datetime-like :: left/right bound for generating dates\n","              periods=None, #optinal - int :: numb of periods to generate\n","              freq='D', #str or DataOffset :: freq str can have multiples, like '5H'\n","              tz=None, #optinal - str, tzinfo :: time zone name to use\n","              inclusive=None #{“both”, “neither”, “left”, “right”} :: include boundaries\n","              ) #return a fixed frequency DatetimeIndex\n","\n","pd.bdate_range(start=None, end=None, periods=None, freq='B', tz=None, inclusive=None\n","               ) #return a fixed frequency DatetimeIndex with business day as the default\n","\n","pd.period_range(start=None, end=None, periods=None, freq=None\n","                ) #return a fixed frequency PeriodIndex\n","\n","pd.timedelta_range(start=None, end=None, periods=None, freq=None\n","                   ) #return a fixed frequency TimedeltaIndex with day as the default\n","\n","pd.infer_freq(index, #DatetimeIndex, TimedeltaIndex :: if is a Series, it will its values\n","              ) #infer the most likely frequency given the input index\n","\n","pd.interval_range(start=None, end=None, periods=None, freq=None, closed='right'#like inclusive\n","                  ) #return a fixed frequency IntervalIndex"]},{"cell_type":"markdown","metadata":{"id":"dZh6FsFE33-A"},"source":["### Series"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iZanfZmHf6d6"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"r6-n6auG364m"},"source":["### DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mM6lVrnNrRSq"},"outputs":[],"source":["df = pd.DataFrame(data=None, index=None, columns=None, dtype=None)"]},{"cell_type":"markdown","metadata":{"id":"BB7QDtDRKv7r"},"source":["#### Attributes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2MHIm1B4sbLy"},"outputs":[],"source":["\n","df.info()   #print a concise summary of a df\n","df.dtypes   #return a Series with the datat type of each col\n","df.index    #return the index (row labels)\n","df.columns  #return the col labels\n","\n","df.attrs    #dictionary of global attributes of this dataset\n","df.values   #return a numpy representation of the df - axes labels will be removed\n","df.empty    #indicator whether is empty\n","\n","df.axes     #return a list representing the axes\n","df.ndim     #return an int representing the number of axes / array dimensions\n","df.size     #return an int representing the number of elements\n","df.shape    #return a tuple representing the dimensionality\n","\n","df.memory_usage() #return the memory usage of each col in bytes"]},{"cell_type":"markdown","metadata":{"id":"--4ADX4IK2Gj"},"source":["#### Data Conversion and Copy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pi-AR_xUv3-H"},"outputs":[],"source":["\n","df = df.astype(dtype,         #data type, dict of col name -> data type\n","               errors='raise' #when 'raise', allow exception to be raised, when 'ignore', suppress exception - return the original\n","              )\n","df = df.convert_dtypes() #convert col to best possible dtypes\n","df = df.copy()           #make a copy of this object's indices and data"]},{"cell_type":"markdown","metadata":{"id":"RHOGpJsRK6Hr"},"source":["#### Slacing & Samples & Values iteration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6IXxzuctxuU9"},"outputs":[],"source":["\n","df.head(n=5) #return the first n rows\n","df.tail(n=5) #return the last n rows\n","\n","df.at[IdxLabel, ColLabel] #access a single value for a row/col label pair\n","df.iat[IdxPos, ColPos]    #access a single value for a row/col pair by integer position\n","\n","df.loc[IdxLabel, ColLabel] #access a group of rows and cols by list of label or a boolean array\n","df.iloc[IdxPos, ColPos]    #access a group of rows and cols by list of integer position\n","\n","df.insert(loc,    #integer position to add the col\n","          column, #str, number, object, label of the inserted column\n","          value,  #scalar, serie, array-like, col data\n","          )\n","\n","df.items()  #iterate over (column labels, values/Series) pairs\n","df.keys()   #get the info axis\n","df.get(key, default=None) #get item from object for given key (eg: df col)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T159yLXCOlF7"},"outputs":[],"source":["\n","#trim values at input threshold(s)\n","df.clip(lower=None, #float, array-like, min threshold values, all values below will be set to it\n","        upper=None, #float, array-like, max threshold values, all values above will be set to it\n","        axis=None,  #int, 0 for index, 1 for columns\n","        inplace=False #bool, perform operation in place on the data\n","        )\n","\n","#truncate a Series or DataFrame before and after some index value\n","df.truncate(before=None, after=None #data,str, int :: truncate all rows before/after this index val\n","            axis=0, copy=True)\n","\n","#align two objects on their axes - the keys are the entire row/col\n","df, other = df.align(other, join='outer', #‘outer’, ‘inner’, ‘left’, ‘right’ :: type of join\n","                     axis=None, level=None, copy=True, fill_value=None,\n","                     method=None, limit=None, fill_axis=0, broadcast_axis=None)\n","\n","#return a random sample of items from an axis of object\n","df.sample(n,             #optional - int :: numb of items from axis to return - n=1 if frac=None\n","          frac,          #optional, float :: fraction of axis items to return - cannot be used with 'n'\n","          replace=False, #bool :: allow or disallow sampling replace\n","          weights,       #optional, str or ndarray-like :: is the probability weighting - '=None' will have equal prob.\n","          axis=None, ignore_index=False)\n","\n","#select values at particular time of day (e.g., 9:30AM) - DatetimeIndex\n","df.at_time(time, #datetime.time or str '12:00'\n","           asof=False, axis=0)\n","\n","#select values between particular times of the day (e.g., 9:00-9:30 AM) - DatetimeIndex\n","df.between_time(start_time, end_time, #datetime.time or str '12:00'\n","                inclusive='both',     #“both”, “neither”, “left”, “right” :: include boundaries\n","                axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KyVxIxTrOspi"},"outputs":[],"source":["\n","df.iterrows() #iterate over df rows as (row index, values/Series) 2-tuple - use with for\n","df.itertuples(index=True, name='Pandas') #iterate over df rows as namedtuples\n","\n","#whether each element in the df is containend in values\n","df.isin(values #iterable, Series, DataFrame, dict :: label need to match, for series is the index, for dataframe is both index and col labels and for dict is the key and col labels\n","        )"]},{"cell_type":"markdown","metadata":{"id":"leanMIMELw03"},"source":["#### Operations & Apply functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SqTu33_64jIP"},"outputs":[],"source":["\n","##other: scalar, sequence, Series, dict, DataFrame - the data to add\n","##df.add(df1) == df+df1, the same is valid for (sub,-), (mul,*),\n","##   (div,/), (floordiv,//), (mod,%), (pow,**)    -  all is element-wise op\n","df.add(other, axis='columns', level=None, fill_value=None)\n","\n","df.dot(other) #matrix multiplication between df and other\n","\n","##df.eq(df1) == df==df1, the same is valid for (ne,!=), (le,<=),\n","##   (lt,<), (ge,>=), (gt,>)      -  all is element-wise op\n","df.eq(other, axis='columns', level=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G2hN9S6_7OOr"},"outputs":[],"source":["\n","##axis: 0 for index, 1 for columns\n","##func: python function, str(func name), list of PyFunc/FuncName or dict of axis labels -> PyFunc/FuncName\n","##raw:  if False pass row/col as Series, if True, pass as ndarray obj\n","\n","df.apply(PyFunc, axis=0, raw=False) #apply a function along an axis\n","df.applymap(PyFunc, na_action=None) #apply a function to a df element-wise\n","df.aggregate(func=None, axis=0)     #aggregate using one or more operations over the specified axis\n","df.transform(func, axis=0)          #call func on self producing a DataFrame with the same axis shape as self"]},{"cell_type":"markdown","metadata":{"id":"JbivDYF7L2Ih"},"source":["#### Computation / Stats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MG_yuTqa_ncy"},"outputs":[],"source":["\n","##axis:    0 for index, 1 for columns\n","##inplace: bool - perform operation in place on the data\n","##skipna:  bool :: exclude Na/Null values\n","##periods: int :: periods to shift for calculating difference\n","##ddof:    int :: delta degrees of freedom\n","##numeric_only: bool :: include only float, int, boolean cols, if None, will use everything\n","\n","\n","df.all() #return True if all elements are True, False if at least one element are False/Zero/Empty\n","df.any() #return True if at least one elements are True, False if all element are False/Zero/Empty\n","\n","#generate descriptive statistics\n","df.describe(percentiles,              #optional - list-like of number :: the percentiles to include in the output, ex. [.25, .60]\n","            include,                  #optional - 'all' for all cols OR list-like of dtype for only col with that type OR None all numeric columns\n","            exclude,                  #optional - list-like of dtype to exclude col with that type OR None to exclude nothing\n","            datetime_is_numeric=False #bool :: treat datetime dtypes as numeric\n","            )\n","\n","#compute pairwise correlation of columns, excluding NA/null values.\n","df.corr(method='pearson', #method to use - {‘pearson’, ‘kendall’, ‘spearman’} or callable\n","        min_periods=1,    #optional - min numb of observations required per pair - only for pearson and spearman\n","        numeric_only=True)\n","\n","#compute pairwise correlation - index and cols labels are the same in both df\n","df.corrwith(other,      #DataFrame, Series\n","            drop=False, #drop missing indices from result\n","            axis=0, method='pearson', numeric_only=True)\n","\n","#compute pairwise covariance of columns, excluding NA/null values - return a covariance matrix\n","df.cov(min_periods=None #optional - min numb of observations required per pair\n","       ddof=1, numeric_only=True)\n","\n","#compute a cumulative X over a DataFrame or Series axis\n","df.cummax(axis=0, skipna=True)  #cumulative maximum\n","df.cummin(axis=0, skipna=True)  #cumulative minimum\n","df.cumprod(axis=0, skipna=True) #cumulative product\n","df.cumsum(axis=0, skipna=True)  #cumulative sum\n","\n","df.diff(periods=1,axis=0) #first discrete difference of element\n","\n","df.abs() #return a Series/DataFrame with absolute numeric value of each element - all elements are numeric\n","\n","df.count(axis=0, numeric_only=False) #count non-NA cells for each column or row\n","df.nunique(axis=0, dropna=True)      #count number of distinct elements in specified axis\n","\n","df.mean(axis=0, skipna=True, numeric_only=None)   #return the mean of the values over the requested axis\n","df.median(axis=0, skipna=True, numeric_only=None) #return the median of the values over the requested axis\n","df.mode(axis=0, skipna=True, numeric_only=None)   #return the mode of the values over the requested axis\n","df.std(axis=None, skipna=True, ddof=1) #return sample standard deviation over requested axis\n","df.var(axis=None, skipna=True, ddof=1) #return unbiased variance over requested axis\n","df.sem(axis=None, skipna=True, ddof=1) #return unbiased standard error of the mean over requested axis\n","\n","df.prod(axis=0, skipna=True, numeric_only=None)   #return the product of the values over the requested axis\n","df.sum(axis=0, skipna=True)                       #return the sum of the values over the requested axis\n","df.max(axis=0, skipna=True, numeric_only=None)    #return the maximum of the values over the requested axis - df.idmax() to get the max index (the fisrt occurrence)\n","df.min(axis=0, skipna=True, numeric_only=None)    #return the minimum of the values over the requested axis - df.idmin() to get the min index (the fisrt occurrence)\n","\n","df.kurt(axis=0, skipna=True, level=None, numeric_only=None)     #return unbiased kurtosis over requested axis\n","df.kurtosis(axis=0, skipna=True, level=None, numeric_only=None) #return unbiased kurtosis over requested axis -\n","df.skew(axis=0, skipna=True)                                    #return unbiased skew over requested axis\n","\n","#percentage change between the current and a prior element\n","df.pct_change(periods=1, fill_method='pad', #str :: how handle NAs before computing percent changes\n","              limit=None #int :: numb of consecutive NAs to fill before stopping\n","              )\n","\n","#return values at the given quantile over requested axis\n","df.quantile(q=0.5, #the quantile to compute\n","            interpolation='linear', #optional - ‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’ :: specifies the interpolation method to use\n","            axis=0, method='single')\n","\n","#compute numerical data ranks (1 through n) along axis\n","df.rank(axis=0, numeric_only, #optional\n","        method='average',     #‘average’, ‘min’, ‘max’, ‘first’, ‘dense’ :: how to rank records with the same value\n","        na_option='keep',     #{‘keep’: assign NaN rank, ‘top’: assign lowest rank, ‘bottom’: assign highest rank} :: how to rank NaN values\n","        ascending=True,       #bool :: ranked in ascending order\n","        pct=False             #bool :: returned rankings in percentile form\n","        )\n","\n","#return a Series containing counts of unique rows in the DataFrame\n","df.value_counts(subset=None, #optional - list-like of cols to use\n","                normalize=False, sort=True, ascending=False, dropna=True)\n"]},{"cell_type":"markdown","metadata":{"id":"05Pr_WcgObrg"},"source":["#### Reindexing n Renames"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RFR8LHACAg2N"},"outputs":[],"source":["\n","##axis:   0 for index, 1 for columns\n","##labels: single label or list-like of labels :: index/cols labels to drop\n","##mapper: dict-like or func :: apply to axis' values - use dict like this: {'OldLabel': 'NewLabel'}\n","##fill_value:    scalar :: value to use for missinf values\n","##index/columns: alternative to specigying axis (`mapper/labels, axis=1/0` is equivalent to `columns/index=mapper/labels`)\n","\n","\n","df.add_prefix(prefix) #prefix cols labels with string - before each label\n","df.add_suffix(suffix) #suffix cols labels with string - after each label\n","\n","df.reset_index(drop=False, inplace=False)  #reset the index, or a level of it, and use the default one instead\n","df.reindex(list_of_labels, fill_value=nan) #conform Series/DataFrame to new index\n","\n","df.rename(mapper, index=None, columns=None, axis=0, inplace=False)           #alter axes labels\n","df.rename_axis(mapper=None, index=None, columns=None, axis=0, inplace=False) #set the name of the axis for the index or columns\n","df.set_axis(labels, axis=0, inplace=False, copy=True)                        #assign desired index to given axis\n","\n","#set the DataFrame index using existing columns\n","df.set_index(keys, #label :: array-like of labels, cols that will be the new index\n","             drop=True, #bool :: delete col to be used as the new index\n","             inplace=False)\n"]},{"cell_type":"markdown","metadata":{"id":"G2XUU00VPC19"},"source":["#### Duplicates n Data equal"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ug1wzbYePEG5"},"outputs":[],"source":["##axis:   0 for index, 1 for columns\n","##keep:   {‘first’:'mark first occurrence', ‘last’:'mark last occurrence', False:'mark all'} :: method to mark or not as True a duplicate\n","##subset: optional - col label or seq of labels, only consider certain col to identigy duplicates, by default use all\n","##labels: single label or list-like of labels :: index/cols labels to drop\n","##index/columns: alternative to specigying axis (`mapper/labels, axis=1/0` is equivalent to `columns/index=mapper/labels`)\n","\n","df.drop(labels, index=None, columns=None, axis=0, inplace=False, errors='raise') #drop specified labels from rows or columns\n","df.drop_duplicates(subset, keep='first',inplace=False, ignore_index=False)       #return DataFrame with duplicate rows removed\n","\n","df.duplicated(subset=None, keep='first') #return boolean Series denoting duplicate rows\n","df.equals(other) #test whether two objects contain the same elements and shape\n"]},{"cell_type":"markdown","metadata":{"id":"YnLVIx9XPmWt"},"source":["#### Missing data handling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kdx_znfCAl0e"},"outputs":[],"source":["\n","##axis:  0 for index, 1 for columns\n","##limit: int, Maximum number of consecutive NaNs to fill\n","\n","\n","df.isna()  #detect missing values - or df.isnull()\n","df.notna() #detect existing (non-missing) values - or df.notnull()\n","\n","\n","#remove missing values\n","df.dropna(axis=0, how='any', #‘any’, ‘all’ :: drop the row if there is any or all are NA values\n","          inplace=False)\n","\n","#fill NA/NaN values using the specified method\n","df.fillna(value,       #scalar, dict, series, dataframe :: value to use to fill holes or specifying the value to use in each index/col\n","          method=None, #‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None :: method used to filling holes\n","          axis=0, limit=None, inplace=False)\n","\n","#fill NaN values using an interpolation method\n","df.interpolate(method='linear', #str :: interpolation technique to use\n","               axis=0, limit, inplace=False)\n","\n","#replace values given in to_replace with value\n","df.replace(to_replace=None, #str, regex, list, dict, Series, scalar, None :: how to find the values to be replaced\n","           value=None,      #scalar, dict, list, str, reges, None :: values to replace any values matching to_replace with\n","           regex=False,     #bool :: whether to interpret to_replace and/or value as regular expressions\n","           method=None,     #‘pad’, ‘ffill’, ‘bfill’ :: method use for replacement - to_replace is a scalar, list or tuple and value is None\n","           inplace=False, limit=None)"]},{"cell_type":"markdown","metadata":{"id":"5PJbMyNWQjCa"},"source":["#### Reshaping & Sorting & Transposing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QOAfGxMaAopd"},"outputs":[],"source":["\n","##axis:    0 for index, 1 for columns\n","##index:   optional - str, object, list of str :: cols used to make new frame's index, if none, uses existing ones\n","##columns: str, object, list of str :: cols used to make new frame's columns\n","##values:  optional - str, object, list of the previous :: cols used to populate new frame's values\n","##keep:    {‘first’: prioritie the first occurence, ‘last’: prioritie the last occurence, ‘all’: don't drop any duplicates}\n","##level:   int, str, list-like, position, label, list of position/label of levels\n","##n:       int :: numb of items to retrieve\n","##ignore_index: bool :: if True, index will be 0, 1, ..., n-1\n","\n","\n","df.transpose() #transpose index and columns - same as 'df.T'\n","\n","#sort by the values along either axis\n","df.sort_values(by,               #str, list of str :: index/cols labels\n","               ascending=True,   #bool, list of bool :: False for descending\n","               kind='quicksort', #‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’ :: Choice of sorting algorithm\n","               inplace=False, axis=0, ignore_index=False)\n","\n","#sort object by labels (along an axis)\n","df.sort_index(axis=0, level=None, ascending=True, inplace=False, kind='quicksort', ignore_index=False,\n","              key=None #optional - callable :: apply the function to the index values befor sorting\n","              )\n","\n","#return reshaped DataFrame organized by given index / column values\n","df.pivot(index,   #optional - str, object, list of str :: cols used to make new frame's index, if none, uses existing ones\n","         columns, #str, object, list of str :: cols used to make new frame's columns\n","         values   #optional - str, object, list of the previous :: cols used to populate new frame's values\n","         )\n","\n","#create a spreadsheet-style pivot table as a DataFrame\n","df.pivot_table(values, index, columns,\n","               aggfunc='mean',  #PyFunc, listf of PyFunc, list of functions passed to calculate the values, dicts: the key is the col and the value the AggFunc\n","               fill_value=None, #scalar :: value to replace missing values\n","               margins=False,   #bool :: add all row/columns (e.g. for sutotal / grand totals)\n","               dropna=True)\n","\n","#unpivot a DataFrame from wide to long format, optionally leaving identifiers set\n","df.melt(id_vars, #optional - tuple, list, or ndarray :: col to use as identifier var\n","        value_vars, #optional - tuple, list, or ndarray :: col to unpivot\n","        ignore_index=True)\n","\n","\n","#return Series/DataFrame with requested index / column level(s) removed\n","df.droplevel(level, axis=0)\n","\n","#rearrange index levels using input order. May not drop or duplicate levels\n","df.reorder_levels(order, #list of int/str :: representing new level order\n","                  axis=0)\n","\n","\n","df.nlargest(columns, n, keep='first')  #return the first n rows ordered by columns in descending order\n","df.nsmallest(n, columns, keep='first') #return the first n rows ordered by columns in ascending order\n","\n","df.to_xarray()        #return an xarray object from the pandas object\n","df.squeeze(axis=None) #squeeze objects - Series or DataFrames with a single element are squeezed to a scalar. DataFrames with a single column or a single row are squeezed to a Series. Otherwise the object is unchanged.\n","\n","\n","#transform each element, that has list-like type, to a row, replicating index values\n","df.explode(column, #str, IndexLabel :: columns to explode\n","           ignore_index=False)"]},{"cell_type":"markdown","metadata":{"id":"h23tmh-JQojB"},"source":["#### Joins"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SdqfYPC7FvIh"},"outputs":[],"source":["\n","##ignore_index: bool, if True, index will be 0, 1, ..., n-1\n","##other/right:  DataFrame, Series/dict-like object, list of these, the data to use\n","##sort:         bool :: if True, order the result by the join key 0 lexicographically\n","##on:           optional - str, list of str/int, col/index levels names :: the keys - both df have\n","##how:          ‘left’, ‘right’, ‘outer’, ‘inner’ :: join methods\n","\n","\n","#append rows of other to the end of caller, returning a new object\n","df.append(other, ignore_index=False, sort=False,\n","          verify_integrity=False #bool :: if True, raise ValueError on creating index with duplicates\n","          )\n","\n","#assign new columns to a DataFrame\n","df.assign(**kwargs #dict of {'ColLabel': callable or Series} :: columns to add\n","          )\n","\n","#compare to another DataFrame and show the differences\n","df.compare(other, align_axis=1, #{0 or ‘index’, 1 or ‘columns’} :: which axis to align the comparison on\n","           keep_shape=False,    #bool :: if true, all rows and columns are kept, otherwise, only the ones with different values\n","           keep_equal=False,    #bool :: if true, keeps values that are equal, otherwise shown them as NaNs\n","           )\n","\n","#join columns of another DataFrame\n","df.join(other, on=None, sort=False, how='left',\n","        lsuffix='', rsuffix='' #str :: suffix to use from left/right frame's overlapping columns\n","        )\n","\n","#merge DataFrame or named Series objects with a database-style join\n","df.merge(right, how='inner', on=None,\n","         left_on=None, right_on=None,         #label or list :: col or index level names to join on in the left/right df\n","         left_index=False, right_index=False, #bool :: use index from the left/right df as the join key\n","         sort=False, suffixes=('_x', '_y'),   #list-like :: a length-2 sequence of suffix to add to overlapping cols names in left and tight respectively\n","         )\n","\n","#modify in place using non-NA values from another DataFrame\n","df.update(other,       #at least one index/col label match\n","          join='left', #only this is implemented\n","          )"]},{"cell_type":"markdown","metadata":{"id":"HNDLl-Fi38b8"},"source":["### [Data Types](https://pandas.pydata.org/docs/reference/arrays.html#pandas-arrays-scalars-and-data-types)"]},{"cell_type":"markdown","metadata":{"id":"t9uAsywLP1ny"},"source":["For most data types, pandas uses NumPy arrays as the concrete objects contained with a Index, Series, or DataFrame."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8GtoD1uNPpRj"},"outputs":[],"source":["#create an array\n","pd.array(data, #sequence of objs\n","         dtype=None)\n","\n","#represents a period of time\n","pd.Period(value=None, #Period, str :: the time period represented - the entire period itself\n","          freq=None,  #str or DataOffset :: freq str can have multiples, like '5H'\n","          )\n","\n","#represents a duration, the difference between two dates or times\n","pd.Timedelta(value=obj, #Timedelta, np.timedelta64, str, int\n","             )\n","\n","#immutable object implementing an Interval, a bounded slice-like interval\n","pd.Interval(left, right,   #orderable scalar :: left/right bound for the interval\n","            closed='right' #‘right’, ‘left’, ‘both’, ‘neither’\n","            )\n","\n","#array of integer (optional missing) values\n","pd.arrays.IntegerArray(values, #numpy.ndarray :: 1-d integer-dtype array\n","                       mask,   #numpy.ndarray :: 1-d bool-dtype array indicating missing values\n","                       )\n","\n","#type for categorical data with the categories and orderedness\n","pd.CategoricalDtype(categories, #optional - sequence :: unique non-null elements, stored in an Index\n","                    ordered     #bool :: if it'll be treated as a ordered categorical\n","                    )\n","\n","#an ExtensionArray for storing sparse data\n","pd.arrays.SparseArray(data,         #array-like, scalar :: a dense array of values to store\n","                      sparse_index, #optional - SparseIndex\n","                      )\n","\n","pd.StringDtype() #extension dtype for string data\n","\n","#array of boolean (True/False) data with missing values\n","pd.arrays.BooleanArray(values, #numpy.ndarray :: 1-d bool-dtype array with the data\n","                       )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wo3SlGrKQO-x"},"outputs":[],"source":["# Timestamp\n","\n","#pandas replacement for python datetime.datetime object\n","ts = pd.Timestamp(ts_input=obj,   #datetime-like, str, int, float :: value to be converted\n","                  freq=None, tz=None, unit=None,\n","                  year, month, day,        #int\n","                  hour, minute, second,    #optinal - int\n","                  microsecond, nanosecond, #optinal - int\n","                  )\n","\n","#Properties from `ts`\n","# .day / .dayofweek / .dayofyear / .daysinmonth\n","# .is_leap_year / .is_month_end/start / .is_quarter_end/start / .is_year_end/start\n","# .max / .microsecond / .min / .minute / .month / .nanosecond / .quarter / .second\n","# .tz / .tzinfo / .value / .week / .weekofyear / .year\n","\n","#Methods\n","##tz: str, pytz.timezone :: time zone of converted timestamp\n","\n","pd.Timestamp.now(tz=None)        #return new Timestamp object representing current time local to tz\n","pd.Timestamp.today(tz=None)      #return the current time in the local timezone\n","pd.Timestamp.combine(date, time) #combine datetime .date, .time into datetime with same date and time fields\n","\n","ts.to_numpy()      #convert the Timestamp to a NumPy datetime64\n","ts.month_name()    #return the month name of the Timestamp with specified locale\n","ts.weekday()       #return the day of the week represented by the date - Monday == 0 … Sunday == 6\n","ts.day_name()      #return the day name of the Timestamp with specified locale\n","ts.time()          #return time object with same time but with tzinfo=None\n","ts.timestamp()     #return POSIX timestamp as float\n","ts.to_datetime64() #return a numpy.datetime64 object with ‘ns’ precision\n","ts.normalize()     #normalize Timestamp to midnight, preserving tz information\n","ts.astimezone(tz)  #convert timezone-aware Timestamp to another time zone\n","\n","#implements datetime.replace, handles nanoseconds\n","ts.replace(year, month, day, hour, minute,  #optional - int\n","           second, microsecond, nanosecond, #optional - int\n","           tzinfo   #pytz.timezone\n","           )\n","\n","#return a formatted string of the Timestamp\n","ts.strftime(format #str :: date format, like \"%d/%m/%Y\"\n","            )\n"]},{"cell_type":"markdown","metadata":{"id":"pwdZGejFWrxW"},"source":["Other data types:\n","\n","\n","\n","*   Timedeltas: NumPy can natively represent timedeltas. pandas provides Timedelta for symmetry with Timestamp\n","\n","*   Periods: represents spans of times as Period objects\n","\n","*   Intervals: arbitrary intervals can be represented as Interval objects\n","\n","*   Nullable Integer: numpy.ndarray cannot natively represent integer-data with missing values. pandas provides this through arrays.IntegerArray\n","\n","*   Categoricals: pandas defines a custom data type for representing data that can take only a limited, fixed set of values. The dtype of a Categorical can be described by a CategoricalDtype\n","\n","*   Sparse: Data where a single value is repeated many times (e.g. 0 or NaN) may be stored efficiently as a arrays.SparseArray\n","\n","*   Strings: when working with text data, where each valid element is a string or missing, we recommend using StringDtype\n","\n","*   Nullable Boolean: the boolean dtype (with the alias \"boolean\") provides support for storing boolean data (True, False) with missing values, which is not possible with a bool numpy.ndarray"]},{"cell_type":"markdown","metadata":{"id":"R7iDwLp-4ElJ"},"source":["### GroupBy"]},{"cell_type":"markdown","metadata":{"id":"hKaTvBVKwpoM"},"source":["GroupBy objects are returned by groupby calls: `pandas.DataFrame.groupby()`, `pandas.Series.groupby()`, etc."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f2K5BOvg4nmE"},"outputs":[],"source":["#group DataFrame using a mapper or by a Series of columns\n","gb = df.groupby(axis=0, by,    #mapping, function, label, list of labels :: used to determine the groups\n","                as_index=True, #bool :: return the groups labels as index\n","                sort=True,     #bool :: sort group keys\n","                )\n","\n","# property\n","gb.groups #Dict {group name -> group labels}\n","gb.index  #Dict {group name -> group indices}\n","gb.get_group(name) #construct DataFrame from group with provided name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mb2-xZOKwrTe"},"outputs":[],"source":["#apply function func group-wise and combine the results together\n","gb.apply(func #callable :: take a df as its first arg and returns a df/series/scalar\n","        )\n","\n","#aggregate using one or more operations over the specified axis - also gb.agg(func)\n","gb.aggregate(func #function, str, list or dict :: function to use for aggregating the data - like mean, sum\n","             )\n","\n","#call function producing a same-indexed DataFrame on each group\n","gb.transform(func #function :: function to apply to each group\n","             )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7GPz7l41UOmT"},"outputs":[],"source":["##axis:         0 for index, 1 for columns\n","##ddof:         int :: degrees of freedom\n","##skipna:       bool :: ignore nan values\n","##limit:        int :: maximum number of consecutive NaNs to fill\n","##min_count:    int :: required numb of valid values\n","##numeric_only: bool :: include only float, int, boolean cols, if None, will use everything\n","\n","\n","gb.all(skipna=True) #return True if all values in the group are truthful, else False\n","gb.any(skipna=True) #return True if any value in the group is truthful, else False\n","\n","\n","gb.size()  #compute group sizes\n","gb.count() #compute count of group, excluding missing values\n","gb.ohlc()  #compute open, high, low and close values of a group, excluding missing values\n","\n","gb.mean(numeric_only=True)        #compute mean of groups, excluding missing values\n","gb.median(numeric_only=True)      #compute median of groups, excluding missing values\n","gb.std(ddof=1, numeric_only=True) #compute standard deviation of groups, excluding missing values\n","gb.var(ddof=1, numeric_only=True) #compute variance of groups, excluding missing values\n","gb.sem(ddof=1, numeric_only=True) #compute standard error of the mean of groups, excluding missing values\n","\n","gb.sum(numeric_only=True, min_count=0)    #compute sum of group values\n","gb.prod(numeric_only=True, min_count=0)   #compute prod of group values\n","gb.max(numeric_only=False, min_count=- 1) #compute max of group values\n","gb.min(numeric_only=False, min_count=-1)  #compute min of group values\n","\n","\n","gb.cumcount(ascending=True, #bool :: if false, number in reverse, from length of group\n","            numeric_only=False) #number each item in each group from 0 to the length of that group - 1\n","\n","gb.cummax(axis=0, numeric_only=False) #cumulative max for each group\n","gb.cummin(axis=0, numeric_only=False) #cumulative min for each group\n","gb.cumprod(axis=0)                    #cumulative product for each group\n","gb.cumsum(axis=0)                     #cumulative sum for each group\n","\n","\n","gb.first(numeric_only=False, min_count=-1) #compute the first non-null entry of each column\n","gb.last(numeric_only=False, min_count=- 1) #compute the last non-null entry of each column\n","\n","gb.head(n=5) #return first n rows of each group\n","gb.tail(n=5) #return last n rows of each group\n","\n","gb.ngroup(ascending=True) #cumber each group from 0 to the number of groups - 1 ; a enumerative complement of cumcount\n","\n","#take the nth row from each group if n is an int, otherwise a subset of rows\n","gb.nth(n, #int, slice, list of ints/slices :: to select the rows to return\n","       dropna=None)\n","\n","#provide the rank of values within each group\n","gb.rank(method='average', #{‘average’: avg rank of group, ‘min’: lowest rank in group, ‘max’: highest rank in group, ‘first’: assigned in order they appear}\n","        na_option='keep', #‘keep’, ‘top’, ‘bottom’\n","        pct=False,        #bool :: comput percentage rank of data within each group\n","        ascending=True, axis=0)\n","\n","gb.pct_change(periods=1, fill_method='ffill', limit=None, freq=None, axis=0) #calculate pct_change of each value to previous entry in group"]},{"cell_type":"markdown","metadata":{"id":"pL9JtffW4nxE"},"source":["### Resampling"]},{"cell_type":"markdown","metadata":{"id":"vtNPGWyonj6j"},"source":["Resampler objects are returned by resample calls: `pandas.DataFrame.resample()`, `pandas.Series.resample()`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YU-ie1e94wT-"},"outputs":[],"source":["#resample time-series data - can be use with a .aggFunc()\n","rsple = resample(rule,        #DateOffset, Timedelta, str :: the offset string/object representing target conversion\n","                 closed=None, #‘right’, ‘left’ :: which side of bin interval is closed\n","                 label=None,  #‘right’, ‘left’ :: which bin edge label to label bucket with\n","                 kind=None,   #{‘timestamp’: convert to a DateTimeIndex, ‘period’: convert to a PeriodIndex}\n","                 axis=0)\n","\n","rsple.groups  #Dict {group name -> group labels}\n","rsple.indices #Dict {group name -> group indices}\n","rsple.get_group(name, obj=None) #construct DataFrame from group with provided name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8_lLJsaKdSvp"},"outputs":[],"source":["##func:  function, str, list or dict :: function to use for aggregating the data\n","##limit: optional - int :: limit of how many values to fill\n","\n","\n","rsple.apply(func=None)     #aggregate using one or more operations over the specified axis\n","rsple.aggregate(func=None) #aggregate using one or more operations over the specified axis\n","\n","#call function producing a like-indexed Series on each group\n","rsple.transform(arg #function :: to apply to each group\n","                )\n","\n","rsple.ffill(limit)   #forward fill the values\n","rsple.nearest(limit) #resample by using the nearest value\n","\n","#fill missing values introduced by upsampling\n","rsple.fillna(method, #{‘pad’, ‘backfill’, ‘ffill’, ‘bfill’, ‘nearest’}\n","                      #‘pad’/‘ffill’: use previous valid observation to fill gap (forward fill).\n","                      #‘backfill’ or ‘bfill’: use next valid observation to fill gap.\n","                      #‘nearest’: use nearest valid observation to fill gap.\n","             limit=None)\n","\n","#return the values at the new freq, essentially a reindex\n","rsple.asfreq(fill_value #optional - scalar :: value to use for missing values\n","             )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wczndlp7fVkY"},"outputs":[],"source":["##numeric_only: bool :: include only float, int, boolean cols, if None, will use wverything\n","##min_count:    int :: required numb of valid values\n","##ddof:         int :: degrees of freedom\n","\n","\n","rsple.size()    #compute group sizes\n","rsple.count()   #compute count of group, excluding missing values\n","rsple.nunique() #return number of unique elements in the group\n","rsple.ohlc()    #compute open, high, low and close values of a group, excluding missing values\n","\n","rsple.first(numeric_only=False, min_count=-1) #compute the first non-null entry of each column\n","rsple.last(numeric_only=False, min_count=-1)  #compute the last non-null entry of each column\n","\n","rsple.mean(numeric_only=True)         #compute mean of groups, excluding missing values\n","rsple.median(numeric_only=True)       #compute median of groups, excluding missing values\n","rsple.sem(ddof=1, numeric_only=True)  #compute standard error of the mean of groups, excluding missing values\n","rsple.std(ddof=1, numeric_only=False) #compute standard deviation of groups, excluding missing values\n","rsple.var(ddof=1, numeric_only=False) #compute variance of groups, excluding missing values\n","\n","rsple.sum(numeric_only=True, min_count=0)   #compute sum of group values\n","rsple.prod(numeric_only=True, min_count=0)  #compute prod of group values\n","rsple.max(numeric_only=False, min_count=-1) #compute max of group values\n","rsple.min(numeric_only=False, min_count=-1) #compute min of group values\n","\n","#return value at the given quantile\n","rsple.quantile(q=0.5 #float, array-like float :: quantiles to return\n","               )"]},{"cell_type":"markdown","metadata":{"id":"7PgIEBNG4wge"},"source":["### Window"]},{"cell_type":"markdown","metadata":{"id":"wto3Q8r3qzIc"},"source":["Rolling objects are returned by .rolling calls: `pandas.DataFrame.rolling()`, `pandas.Series.rolling()`, etc.\n","\n","Expanding objects are returned by .expanding calls: `pandas.DataFrame.expanding()`, `pandas.Series.expanding()`, etc.\n","\n","ExponentialMovingWindow objects are returned by .ewm calls: `pandas.DataFrame.ewm()`, `pandas.Series.ewm()`, etc."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SKxwMhA4zrJ"},"outputs":[],"source":["#provide rolling window calculations - use with a .aggFunc()\n","rolling = df.rolling(window,              #int, offset, BaseIndexer :: size of the moving window\n","                     min_periods=None,    #int :: min numb of observations in window\n","                     center=False,        #bool :: set windows labels as the right (if True, the center) edge of the window index\n","                     axis=0, closed=None, #'right'/'left'/'both'/'neither' :: first/last/no/first and left point is excluded\n","                     )\n","\n","#provide expanding window calculations (unlike rolling, this uses all the data) - use with a .aggFunc()\n","df.expanding(min_periods=1, center=None, axis=0, method='single')\n","\n","#provide exponentially weighted (EW) calculations - use with a .aggFunc()\n","df.ewm(com=None, span=None, min_periods=0,\n","       alpha=None,    #optional - specify smoothing factor alfa directly\n","       halflife=None, #optional - float :: specify decay in terms of center of mass/span/half-life\n","       adjust=True,   #bool :: divide by decaying djustment factor in beginning periods\n","       ignore_na=False, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILRkesYMugPD"},"outputs":[],"source":["# Agg to use with - `rolling.aggFunc()` - also valid for `expanding` and `ewm`\n","#   .count() - .sum() - .mean() - .median() - .var() - .std() - .min() - .max()\n","#   .corr() - .cov() - .skew() - .kurt() - .sem() - .rank()\n","\n","\n","#calculate the rolling custom aggregation function\n","rolling.apply(func,     #function :: must produce a single value\n","              raw=False #if False pass row/col as Series, if True, pass as ndarray obj\n","              )\n","\n","#aggregate using one or more operations over the specified axis\n","rolling.aggregate(func #function, str, list, dict :: to agg the data\n","                  )\n","\n","#calculate the rolling quantile\n","rolling.quantile(quantile,               #float :: the quantile\n","                 interpolation='linear', #{'linear':i+(j-i)*fraction,'lower': i, ‘higher’: j, ‘midpoint’:(i+j)/2, ‘nearest’: between i and j}\n","                 numeric_only=False      #bool :: include only float, int, boolean cols, if None, will use wverything\n","                 )"]},{"cell_type":"markdown","metadata":{"id":"_hRHah6Ml0DI"},"source":["## *Pandas Profiling*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7S69bUCwl3dp"},"outputs":[],"source":["from pandas_profiling import  ProfileReport\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1671054299241,"user":{"displayName":"Salomao Alves","userId":"01229308303208121589"},"user_tz":180},"id":"CzrI5y8ql-Ax","outputId":"ba44796c-74ad-4dff-cc1d-3b59958b498e"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-2c78cb55-23a0-4bc7-bb8a-a1ea9697319f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Team</th>\n","      <th>League</th>\n","      <th>Round 1</th>\n","      <th>Round 2</th>\n","      <th>Round 3</th>\n","      <th>Round 4</th>\n","      <th>Final</th>\n","      <th>Date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A</td>\n","      <td>Z</td>\n","      <td>82</td>\n","      <td>5</td>\n","      <td>10.0</td>\n","      <td>26.0</td>\n","      <td>99</td>\n","      <td>2002-09-08</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c78cb55-23a0-4bc7-bb8a-a1ea9697319f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2c78cb55-23a0-4bc7-bb8a-a1ea9697319f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2c78cb55-23a0-4bc7-bb8a-a1ea9697319f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["  Team League  Round 1  Round 2  Round 3  Round 4  Final        Date\n","0    A      Z       82        5     10.0     26.0     99  2002-09-08"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.DataFrame([['A', 'Z', 82, 5, 10, 26, 99, '2002-09-08'],  ['B', 'Y', 103, 25, 15, 21, 99, '2202-06-08'],\n","                   ['A', 'Y', 10, 13, np.nan, 25, 99, '2012-06-08'], ['B', 'Z', 100, 25, np.nan, 20, 99, '2002-09-08'],\n","                   ['C', 'Y', 14, 15, 19, np.nan, 99, '2102-09-08'], ['D', 'Z', 1699, 18, 11, np.nan, 98, '2002-09-08'],\n","                   ['C', 'Z', 93, 15, 17, np.nan, 99, '2002-06-08'], ['D', 'Y', 130, 19, 13, np.nan, 98, '2002-09-08']],\n","                  columns=['Team', 'League', 'Round 1', 'Round 2', 'Round 3', 'Round 4', 'Final', 'Date'])\n","df.head(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":1308,"status":"error","timestamp":1671054428648,"user":{"displayName":"Salomao Alves","userId":"01229308303208121589"},"user_tz":180},"id":"oWJUmgivmRDi","outputId":"e0087552-64b4-47b3-c21b-295ac9acecf1"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-aea6365621c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#use 'minimal=True' when has +20 features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#profile.to_file(output_file='report_name.html') #export as file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_notebook_iframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#show in jupyter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas_profiling/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mdescription_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         self.html = to_html(sample,\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas_profiling/describe.py\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(df, bins, check_correlation, correlation_threshold, correlation_overrides, check_recoded, pool_size, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0mvariable_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0mvariable_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: concat() got an unexpected keyword argument 'join_axes'"]}],"source":["profile = ProfileReport(df, title='Report Title') #use 'minimal=True' when has +20 features\n","#profile.to_file(output_file='report_name.html') #export as file\n","profile.to_notebook_iframe() #show in jupyter\n"]},{"cell_type":"markdown","metadata":{"id":"E8ek6N--dDhk"},"source":["# **Better Performance**"]},{"cell_type":"markdown","metadata":{"id":"SgPolZdOdGo_"},"source":["numba: compilador JIT (just in time), permiet compilar durante a execução do programa\n","\n","dask: faz computação paralelizadas, usada junto cm o numba\n","\n","Vaex: high performance DataFrame library enabling efficient, out-of-core computing for large datasets comprising millions or billions of samples."]},{"cell_type":"markdown","metadata":{"id":"VyN_m92vAKvj"},"source":["# **Web**"]},{"cell_type":"markdown","metadata":{"id":"TT6pgS1lEWhD"},"source":["## *Flask*"]},{"cell_type":"markdown","metadata":{"id":"xLmEQ7f_Ee_t"},"source":["It is a Web Application Framework, a collection of libraries and modules that enable devs to write application without worrying about low-level detail, written in Python.\n","\n","Developed by Armin Ronacher, is based on the Werkzeg WSGI tooklit and the Jinja2 template engine.\n","\n","The application can have the following folders/files:\n","*   file main.py: main app code\n","*   folder media_files:\n","*   folder static: place images, javascript and css files - files that do not need a Python backend\n","*   folder templates: has the html pages with the variables\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rrZyV0cKEYiy"},"outputs":[],"source":["import os\n","from flask import Flask, render_template, request, url_for, current_app\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fis1NOT2EZAn"},"outputs":[],"source":["app = Flask(\"app_name\") # instance of Flask class\n","\n","PROJECT_ROOT = os.path.abspath(os.path.dirname(__file__))\n","app.config['MEDIA_ROOT'] = os.path.join(PROJECT_ROOT, 'media_files')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ljDdBCoFPYH"},"outputs":[],"source":["# can load the app in localhost:5000\n","\n","@app.route(\"/\", methods=['GET'])\n","def begin(): # to access the returned page, go to localhost:5000/ - the home\n","  return render_template('Random.html', # this html page need to be in the 'templates' folder\n","                         logo_url='/static/img/logo.png',  # this are varialbles in the html page,\n","                         first_input='Enter value', obs='', # used with Django (same var name)\n","                         action='/youtube' # to which page send the data\n","                         )\n","\n","\n","@app.route(\"/youtube\", methods=['POST']) # use post when receive form/html data\n","def youtube(): # to access the returned page, go to localhost:5000/youtube\n","  n = request.form['form_name'] # get value from the form\n","  return render_template('Display.html', # this html page need to be in the 'templates' folder\n","                         logo_url='/static/img/logo.png', value_form=n\n","                              # this are varialbles in the html page, used with Django (same var name)\n","                         )\n","\n","if __name__ == '__main__':\n","  app.run(debug=True, use_reloader=True)"]},{"cell_type":"markdown","metadata":{"id":"FVNmRaRkGbtJ"},"source":["## *Jinja2*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QV13s4deGfE1"},"outputs":[],"source":["# Base.html - the html that all html will use, as a Template, to create the page format\n","\n","<html>\n","<head>\n","    <meta charset=\"utf-8\">\n","    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n","    <meta name=\"author\" content=\"Salomão Alves\">\n","    <link rel=\"stylesheet\" href=\"../static/css/main.css\">\n","    <script type=\"text/javascript\" src=\"../static/js/d3.min.js\"></script>\n","    <script type=\"module\" src=\"../static/js/main.js\" defer></script>\n","\n","    <title>A Title</title>\n","</head>\n","<body>\n","    {% block topo %} # a block already filled with some default tags - topo is the block name\n","    <header>\n","        <a href=\"{{ url_for('begin') }}\"><img src={{logo_url}} width=\"50\" height=\"50\"></a> Go Home!\n","    </header>   # 'url_for()' is a Flask func and 'logo_url' are parameters passed by the Flask.render_template func\n","    {% endblock %}\n","\n","    {% block info%}<!-- page info -->{% endblock%} # block to determine where add info tags\n","</body>\n","</html>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vOVtosHkHfSV"},"outputs":[],"source":["# Random.html - a html that will use the Base as a template\n","\n","{% extends \"Base.html\" %}\n","{% block info %}\n","<form method=\"POST\" id=\"form\" action={{ action }}>\n","\n","    <div class=\"form-group\">\n","      <label>{{ first_input }}\n","        <input type=\"text\" name=\"form_name\">\n","      </label>\n","    </div>\n","\n","    <button type=\"submit\" onclick=\"showImg()\" class=\"btn btn-primary\">ENTER</button>\n","\n","    <br />{{ obs }}\n","\n","</form>\n","{% endblock %}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d01Ru7A4HShq"},"outputs":[],"source":["# Display.html - other html that will use the Base as a template\n","\n","{% extends \"Base.html\" %}\n","{% block info %}\n","<form method=\"POST\" id=\"form\" action=\"/\">\n","    <ul>\n","        <li><{{ value_form }}</a></li>\n","    </ul>\n","</form>\n","{% endblock %}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SX5UqeVmDJKw"},"outputs":[],"source":["# Examples possibles of operation on html pages\n","\n","{% extends \"Base.html\" %} # identifies which template used\n","{% block info %}  # which block in the template the tags 'll go\n","\n","<html>\n","  <head>\n","    <title>{{ title }}</title>\n","  </head>\n","  <body>\n","    # IF clause - can use and, or, ...\n","    {% if username == \"Rosalia\": %}\n","    <h1>Hello my love</h1>\n","    {% else %}\n","    <h1>Hello {{ username }}</h1>\n","    {% endif %}\n","\n","    # FOR over a list\n","    <ul>\n","      {% for element in var_list: %}\n","      <li>{{ element }}</li>\n","\t    {% endfor %}\n","\t  </ul>\n","\n","    # FOR over a dict\n","    <ul>\n","      {% for element in var_dict -%}\n","      <li>{{element['Comment']}}</li>\n","      <li>{{element['Score']}}</li>\n","\t    {% endfor %}\n","\t  </ul>\n","\n","  </body>\n","</html>\n","\n","{% endblock %}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9jYl16PuHgI5"},"outputs":[],"source":["# TableFromDict.html - a html that will use the Base as a template\n","#     example of how to create a table using a dict\n","\n","{% extends \"Base.html\" %}\n","{% block info %}\n","\n","<div id=\"tfidf\" style=\"display: none;\">\n","    <table class=\"table\">\n","        <tbody>\n","            <tr class=\"if\">\n","                {% for key in var_dict -%}  # a FOR clause for each key in 'var_dict', a dict passed by Flask.render_template\n","                {% if key != 'key5' and key != 'key4'-%}\n","                <td class=\"col\">{{key}}</td>\n","                {% endif %}\n","                {% endfor %}\n","            </tr>\n","\n","            {% for i in var_dict['key5'] -%} # a FOR clause for each value in key - eg. a range of [0, NumbRows], so 'll iteract\n","            <tr>     # here, the value of key1/2 is a list of str, it'll iteract over that; key5 value is a list     # over the dict rows\n","                <td class=\"col\">{{var_dict['Key1'][i]}}</td> # get the value from\n","                <td class=\"col\">{{var_dict['Key2'][i]}}</td> #  any element in the key's list\n","            </tr>\n","            {% endfor %}\n","\n","            {% for info in var_dict -%} # a FOR clause for ...\n","            <tr>\n","                <td class=\"col\">{{info['Comment']}}</td>\n","                <td class=\"col\">{{info['Score']}}</td>\n","            </tr>\n","            {% endfor %}\n","        </tbody>\n","        <h7 style=\"color: red;\">{{var_dict['key4']}}</h7> # to get a direct value - a string\n","    </table>\n","</div>\n","\n","{% endblock %}"]},{"cell_type":"markdown","metadata":{"id":"F6vRip9jItZe"},"source":["## *Dash*"]},{"cell_type":"markdown","metadata":{"id":"J2x0UV9hcnQe"},"source":["A low-code framework for rapidly building data apps in Python.\n","\n","Use only one Dash().layout - aka app.layout\n","  - use a lot of html.Div to divide the structure\n","  - .layout will describes what the app looks like and is a hierarchical tree of components\n","\n","\n","dash.html: can use any tag from the HTML5 and attributes, like style, className, id, n_clicks\n","  - Documentation - https://dash.plotly.com/dash-html-components\n","  - ex: html.H1-5 .Div .Label .\n","\n","dash.dcc: contains higher-level components that are interactive (JS, HTML, CSS)\n","  - Documentation - https://dash.plotly.com/dash-core-components\n","  - ex: dcc.Dropdown .Graph .\n","\n","Callback functions\n","  - are funcs that are automatically called by Dash whenever an input component's\n","  - property changes, in order to update some property in another component (the output)\n","\n","Dash is stateless\n","  - so, to share data across multiple processes or servers, we need to store\n","  - the data somewhere tha is accessible to each of the process\n","  - can be: in user browser (dcc.Store) or on the disk (file or database) or in server-side memory shared acrros processes/servers\n","\n","Custom CSS or JavaScript in the apps\n","  - create a folder named assets in the root of your app directory and include your CSS and JavaScript files in that folder\n","  - Dash automatically serves all the files that are included in this folder\n","  - by default, the URL to request the assets is /assets, but you can customize this with the assets_url_path argument to dash.Dash()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4CU8bS_1cz9K"},"outputs":[],"source":["pip install dash"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":439,"status":"ok","timestamp":1692505474389,"user":{"displayName":"Salomao Alves","userId":"01229308303208121589"},"user_tz":180},"id":"gP3-4g-1L1YU","outputId":"8ad1b9e4-4c2c-4da5-b8cd-bd8e5a21c40e"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 3313 entries, 0 to 3312\n","Data columns (total 6 columns):\n"," #   Column     Non-Null Count  Dtype  \n","---  ------     --------------  -----  \n"," 0   country    3313 non-null   object \n"," 1   continent  3313 non-null   object \n"," 2   year       3313 non-null   int64  \n"," 3   lifeExp    3313 non-null   float64\n"," 4   pop        3313 non-null   int64  \n"," 5   gdpPercap  3313 non-null   float64\n","dtypes: float64(2), int64(2), object(2)\n","memory usage: 155.4+ KB\n","None\n"]}],"source":["import plotly.express as px\n","import pandas as pd\n","from dash import Dash, html, dcc, callback, Output, Input\n","\n","df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminder_unfiltered.csv')\n","all_options = {'America': ['New York City', 'San Francisco', 'Cincinnati'],\n","               'Canada': ['Montréal', 'Toronto', 'Ottawa']}\n","print(df.info())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":671},"executionInfo":{"elapsed":472,"status":"ok","timestamp":1692505944023,"user":{"displayName":"Salomao Alves","userId":"01229308303208121589"},"user_tz":180},"id":"mParUUwJJmmE","outputId":"bc5c01f6-3afa-4826-fb7b-42df0d51f465"},"outputs":[{"data":{"application/javascript":"(async (port, path, width, height, cache, element) => {\n    if (!google.colab.kernel.accessAllowed && !cache) {\n      return;\n    }\n    element.appendChild(document.createTextNode(''));\n    const url = await google.colab.kernel.proxyPort(port, {cache});\n    const iframe = document.createElement('iframe');\n    iframe.src = new URL(path, url).toString();\n    iframe.height = height;\n    iframe.width = width;\n    iframe.style.border = 0;\n    iframe.allow = [\n        'accelerometer',\n        'autoplay',\n        'camera',\n        'clipboard-read',\n        'clipboard-write',\n        'gyroscope',\n        'magnetometer',\n        'microphone',\n        'serial',\n        'usb',\n        'xr-spatial-tracking',\n    ].join('; ');\n    element.appendChild(iframe);\n  })(8050, \"/\", \"100%\", 650, false, window.element)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["from datetime import date\n","\n","app = Dash(__name__)\n","\n","markdown_text = '''\n","### Dash and Markdown\n","Dash apps can be written in Markdown.\n","Dash uses the [CommonMark](http://commonmark.org/)\n","specification of Markdown.\n","'''\n","\n","app.layout = html.Div(children=[     # attributes in style is camelCased - text-align become textAlign\n","  html.H1(children='Title of Dash App', style={'textAlign':'center', 'color': 'pink'}),\n","  html.Div(children='Dash: A web application framework for your data.', className='div_class'),\n","  html.P('A paragraph'),\n","  html.Br(), #\\n - new line\n","  html.Hr(), #draw a big horizontal row\n","  dcc.Tabs(id=\"tabs\", value='dcc-1', children=[\n","          dcc.Tab(label='Dcc01', value='dcc-1'),\n","          dcc.Tab(label='Dcc02', value='dcc-2'),\n","      ]),\n","  html.Div(id='tabs-content')\n","])\n","@callback(Output('tabs-content', 'children'),\n","          Input('tabs', 'value'))\n","def render_content(tab):\n","    if tab == 'dcc-1':\n","        return html.Div([\n","                  dcc.DatePickerSingle(id='date-picker-single', date=date(1997, 5, 10)),\n","                  html.Label('Dropdown'),\n","                  dcc.Dropdown(options=df.country.unique(), value='Canada', multi=False, id='dropdown_selection'),\n","                  html.Label('Radio Items'),\n","                  dcc.RadioItems(options=df.country.unique()[:5], value='Albania', style={'padding': 10, 'flex': 1}),\n","                  html.Label('Checkboxes'),\n","                  dcc.Checklist(options=df.country.unique()[:5], value=['Angola'], style={'padding': 10, 'flex': 1}),\n","                  html.Label('Slider'),\n","                  dcc.Slider(df['year'].min(), df['year'].max(), step=None, value=df['year'].min(),\n","                              marks={str(year): str(year) for year in df['year'].unique()}, id='year-slider'),\n","                ], style={'width': '48%', 'float': 'right', 'display': 'inline-block'})\n","    elif tab == 'dcc-2':\n","        return html.Div([\n","                  dcc.Input(value='Insert a text: ', type='text'),\n","                  dcc.Markdown(children=markdown_text),\n","                  html.Button(id='submit-button-state', n_clicks=0, children='Submit'),\n","                ], style={'width':'50%', 'height':'60px', 'padding-left':'2%', 'display':'inline-block'}),\n","\n","if __name__ == '__main__':\n","    app.run(debug=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":671},"executionInfo":{"elapsed":416,"status":"ok","timestamp":1691887763676,"user":{"displayName":"Salomao Alves","userId":"01229308303208121589"},"user_tz":180},"id":"GzQDh2zQL3Wf","outputId":"1d59eca0-79bf-482f-bc0b-cca4585759a0"},"outputs":[{"data":{"application/javascript":"(async (port, path, width, height, cache, element) => {\n    if (!google.colab.kernel.accessAllowed && !cache) {\n      return;\n    }\n    element.appendChild(document.createTextNode(''));\n    const url = await google.colab.kernel.proxyPort(port, {cache});\n    const iframe = document.createElement('iframe');\n    iframe.src = new URL(path, url).toString();\n    iframe.height = height;\n    iframe.width = width;\n    iframe.style.border = 0;\n    iframe.allow = [\n        'accelerometer',\n        'autoplay',\n        'camera',\n        'clipboard-read',\n        'clipboard-write',\n        'gyroscope',\n        'magnetometer',\n        'microphone',\n        'serial',\n        'usb',\n        'xr-spatial-tracking',\n    ].join('; ');\n    element.appendChild(iframe);\n  })(8050, \"/\", \"100%\", 650, false, window.element)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["\n","def generate_table(dataframe, country, max_rows=10):\n","  dataframe = dataframe[dataframe.country==country]\n","  return html.Table([\n","    html.Thead(\n","      html.Tr([html.Th(col) for col in dataframe.columns])\n","    ),\n","    html.Tbody([\n","      html.Tr([\n","          html.Td(dataframe.iloc[i][col]) for col in dataframe.columns\n","      ]) for i in range(min(len(dataframe), max_rows))\n","    ])\n","  ])\n","\n","app = Dash(__name__)\n","\n","country = 'Canada'\n","fig = px.line(df[df.country==country], x='year', y='pop')\n","\n","app.layout = html.Div([\n","    html.H3('Plot title'),\n","    dcc.Graph(id='fig_id', figure=fig,\n","              # User Interaction attributes - can be useed in the callbacks\n","              #hoverData -- callback when the hover data is showed (pass the mouse over a point)\n","              #relayoutData -- whent user zooms in or out in the plot\n","              #clickData --  when the mouse click in some data point\n","              #selectedData --  when the mouse selecet N data points by dragging the mouse (form squares figures)\n","              ),\n","    html.H4(children='Table by a py func'),\n","    generate_table(df, country)\n","])\n","\n","\n","if __name__ == '__main__':\n","    app.run(debug=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":671},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1691886863004,"user":{"displayName":"Salomao Alves","userId":"01229308303208121589"},"user_tz":180},"id":"N3sg6e5wL39W","outputId":"913a0ac1-c20d-4260-a340-16f80f4cccf3"},"outputs":[{"data":{"application/javascript":"(async (port, path, width, height, cache, element) => {\n    if (!google.colab.kernel.accessAllowed && !cache) {\n      return;\n    }\n    element.appendChild(document.createTextNode(''));\n    const url = await google.colab.kernel.proxyPort(port, {cache});\n    const iframe = document.createElement('iframe');\n    iframe.src = new URL(path, url).toString();\n    iframe.height = height;\n    iframe.width = width;\n    iframe.style.border = 0;\n    iframe.allow = [\n        'accelerometer',\n        'autoplay',\n        'camera',\n        'clipboard-read',\n        'clipboard-write',\n        'gyroscope',\n        'magnetometer',\n        'microphone',\n        'serial',\n        'usb',\n        'xr-spatial-tracking',\n    ].join('; ');\n    element.appendChild(iframe);\n  })(8050, \"/\", \"100%\", 650, false, window.element)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["\n","app = Dash(__name__)\n","\n","countries_radio_var = dcc.RadioItems(list(all_options.keys()), 'America', id='countries-radio',)\n","app.layout = html.Div([\n","  # multiples callback examples\n","  html.Label('Countries radio'),\n","  countries_radio_var, # another way to create a component\n","  html.Label('Cities radio'),\n","  dcc.RadioItems(id='cities-radio'),\n","  html.Div(id='display-selected-values'),\n","\n","  html.Br(),html.Hr(),html.Br(),\n","\n","  # button action/click\n","  dcc.Input(id='input-1-state', type='text', value='Montréal'),\n","  dcc.Input(id='input-2-state', type='text', value='Canada'),\n","  html.Button(id='submit-button-state', n_clicks=0, children='Submit'),\n","  html.Div(id='output-state'),\n","\n","  html.Br(),html.Hr(),html.Br(),\n","\n","  # plot with dropdown\n","  dcc.Dropdown(df.country.unique(), 'Canada', id='dropdown-selection'),\n","  dcc.Graph(id='fig_id'),\n","])\n","\n","# a simple callback (explanation) - for 'plot with dropdown'\n","@callback(\n","  # Output(output_id, output_property) - id can be find in the component definition -- all Output go first\n","  # Input(input_id, input_property) - property and id are the attributes/parameters of some component (dash.html, dash.dcc)\n","  #   _property: can be a value/DropDown, children;style/H1-5;Div, figure/PlotlyPlot, relayoutData/PlotLayoutChange\n","  Output('fig_id', 'figure'),\n","  Input('dropdown-selection', 'value')\n",")\n","def callback_updates(input_val1):#, input_val2, ...):\n","  # @input_valN: the inputs attributes values\n","  # @output_valN: the new value of the output attribute\n","  dff = df[df.country==input_val1]\n","  fig = px.line(dff, x='year', y='pop')\n","  fig.update_layout(transition_duration=500) # transitions allow the chart to update from one state to the next smoothly, as if it were animated\n","  return fig#, output_val2, ...\n","\n","# multiples callbacks, they call each other\n","@callback(\n","  Output('cities-radio', 'options'),\n","  Input(countries_radio_var, 'value')) # another way to pass the component id\n","def set_cities_options(selected_country):\n","  return [{'label': i, 'value': i} for i in all_options[selected_country]]\n","@callback(\n","  Output('cities-radio', 'value'),\n","  Input('cities-radio', 'options'))\n","def set_cities_value(available_options):\n","  return available_options[1]['value']\n","@callback(\n","  Output('display-selected-values', 'children'),\n","  Input(countries_radio_var, 'value'),\n","  Input('cities-radio', 'value'))\n","def set_display_children(selected_country, selected_city):\n","  return f'{selected_city} is a city in {selected_country}'\n","\n","# callbacks with State - only is fired when a action (button click) is made\n","@callback(\n","  Output('output-state', 'children'),\n","  Input('submit-button-state', 'n_clicks'),\n","  State('input-1-state', 'value'), # State hold this value until the Input _property\n","  State('input-2-state', 'value')) # is changed, then the callback is fired\n","def update_output(n_clicks, input1, input2):\n","  return f'''The Button has been pressed {n_clicks} times,\n","             Input 1 is \"{input1}\",and Input 2 is \"{input2}\"'''\n","\n","if __name__ == '__main__':\n","  app.run(debug=True)\n"]},{"cell_type":"markdown","metadata":{"id":"vPuLpyO4cqCD"},"source":["# *AstroML*\n","\n","lib voltada para datamining e ML de dados astronomicos"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO1Qw2gpjeOs+b7+D4EjPgq","collapsed_sections":["VswdO1cPn75A","FndVPxhflLst","zyj1oQwhw33A","EQifVk7U1uE6","mXqvmKjtv0Dg","WQqTKAzobGET","4mhyMiqLbGx6","OLw3ePoirT-Q","HuNxhh38bwFR","6RK3HiPZVHSZ","Ml6uxSvuVLhm","Rh-nd5jMVRtE","3FSZgB1ZVVrO","QOW6EMaBVeae","XVB9xa7CVbku","qfc6ANMLc-c1","dYrEu6hv307w","pT-9EqwN5DzD","bBygxEY9KWLz","0JBezPY9KbXn","rvmaRrcZKfiY","dZh6FsFE33-A","r6-n6auG364m","BB7QDtDRKv7r","--4ADX4IK2Gj","RHOGpJsRK6Hr","leanMIMELw03","JbivDYF7L2Ih","05Pr_WcgObrg","G2XUU00VPC19","YnLVIx9XPmWt","5PJbMyNWQjCa","h23tmh-JQojB","HNDLl-Fi38b8","R7iDwLp-4ElJ","pL9JtffW4nxE","7PgIEBNG4wge","_hRHah6Ml0DI","E8ek6N--dDhk","VyN_m92vAKvj","TT6pgS1lEWhD","FVNmRaRkGbtJ","F6vRip9jItZe"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
