{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you can find here:\n",
    " - Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Time Series*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to convert the timestamp column of Object Data type to pandas-DateTime Data Type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dickey-Fuller test\n",
    "## p-value > 0.05: Fail to reject the null hypothesis (H0), the data has a unit root and is non-stationary.\n",
    "## p-value <= 0.05: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.\n",
    "\n",
    "X = data['close_price'].values\n",
    "\n",
    "result = adfuller(X)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diference Transform\n",
    "\n",
    "NewData = data['close_price'] - data['close_price'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "DATAPATH = './data/stock_prices_sample.csv'\n",
    "\n",
    "data = pd.read_csv(DATAPATH, index_col=['DATE'], parse_dates=['DATE'])\n",
    "data.head(10)\n",
    "\n",
    "data = data[data.TICKER != 'GEF']\n",
    "data = data[data.TYPE != 'Intraday']\n",
    "\n",
    "drop_cols = ['SPLIT_RATIO', 'EX_DIVIDEND', 'ADJ_FACTOR', 'ADJ_VOLUME', 'ADJ_CLOSE', 'ADJ_LOW', 'ADJ_HIGH', 'ADJ_OPEN', 'VOLUME', 'FREQUENCY', 'TYPE', 'FIGI']\n",
    "\n",
    "data.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_moving_average(series, window, plot_intervals=False, scale=1.96):\n",
    "\n",
    "    rolling_mean = series.rolling(window=window).mean()\n",
    "\n",
    "    plt.figure(figsize=(17,8))\n",
    "    plt.title('Moving average\\n window size = {}'.format(window))\n",
    "    plt.plot(rolling_mean, 'g', label='Rolling mean trend')\n",
    "\n",
    "    #Plot confidence intervals for smoothed values\n",
    "    if plot_intervals:\n",
    "        mae = mean_absolute_error(series[window:], rolling_mean[window:])\n",
    "        deviation = np.std(series[window:] - rolling_mean[window:])\n",
    "        lower_bound = rolling_mean - (mae + scale * deviation)\n",
    "        upper_bound = rolling_mean + (mae + scale * deviation)\n",
    "        plt.plot(upper_bound, 'r--', label='Upper bound / Lower bound')\n",
    "        plt.plot(lower_bound, 'r--')\n",
    "\n",
    "    plt.plot(series[window:], label='Actual values')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "\n",
    "#Smooth by the previous 5 days (by week)\n",
    "plot_moving_average(data.CLOSE, 5)\n",
    "\n",
    "#Smooth by the previous month (30 days)\n",
    "plot_moving_average(data.CLOSE, 30)\n",
    "\n",
    "#Smooth by previous quarter (90 days)\n",
    "plot_moving_average(data.CLOSE, 90, plot_intervals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esse código veio de outro lugar - ver se tem algo util nele\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pyramid.arima import auto_arima\n",
    "\n",
    "#cria a base da dados\n",
    "AirPassengers = '/home/salomao/Desktop/Data Science - Udemy/4 - Séries Temporais/Dados/AirPassengers.csv'\n",
    "dateparse = lambda dates: pd.datetime.strptime(dates,'%Y-%m') #transf para tipo de date\n",
    "base = pd.read_csv(AirPassengers, parse_dates=['Month'],index_col='Month',date_parser=dateparse)\n",
    "ts = base['#Passengers']\n",
    "\n",
    "#exibição e slices\n",
    "ts_ano = ts.resample('A').sum() #faz a somatoria por ano\n",
    "ts_mes = ts.groupby([lambda x: x.month]).sum() #faz a somatoria por mes\n",
    "plt.plot(ts_mes)\n",
    "\n",
    "#decomposição\n",
    "decomposicao = seasonal_decompose(ts) #faz a decomposição\n",
    "tendencia = decomposicao.trend #da tendencia\n",
    "sazonal = decomposicao.seasonal #da sozonalidade\n",
    "aleatorio = decomposicao.resid #da aleatoriedade\n",
    "plt.subplot(4,1,1) #plotando o grafico de cada decomposiçao\n",
    "plt.plot(ts, label = 'Original')\n",
    "plt.subplot(4,1,2)\n",
    "plt.plot(tendencia, label = 'Tendencia')\n",
    "plt.subplot(4,1,3)\n",
    "plt.plot(sazonal, label = 'Sazonalidade')\n",
    "plt.subplot(4,1,4)\n",
    "plt.plot(aleatorio, label = 'Aleatório')\n",
    "plt.tight_layout() #configurar o layout\n",
    "\n",
    "#previsão (3 maneiras de fazer)\n",
    "#1: media\n",
    "ts.mean() #grande chances de erro, pois a serie n é estacionaria\n",
    "ts['1960-01-01':'1960-12-31'].mean() #faz a media apenas do ultimo ano\n",
    "#2: media movel\n",
    "media_movel = ts.rolling(window = 12).mean() #calcula a media movel (window = subconj)\n",
    "previsoes = []\n",
    "for i in range(1,13): #coloca as medias das medias moveis no vetor de previsoes\n",
    "    superior = len(media_movel) - i\n",
    "    inferior = superior - 11\n",
    "    previsoes.append(media_movel[inferior:superior].mean())\n",
    "previsoes = previsoes[::-1]\n",
    "plt.plot(previsoes)\n",
    "#3: arima\n",
    "modeo_auto = auto_arima(ts,m=12,seasonal = True, trace=True).summary() #vc acha os valores pra colocar no order abaixo (esta em SARIMAX)\n",
    "modelo = ARIMA(ts, order=(2,1,2)) #cria o modelo\n",
    "modelo_treinado = modelo.fit() #treina o modelo\n",
    "previsoes = modelo_treinado.forecast(steps=12) #realiza as previsoes (qtd de meses previstos)\n",
    "eixo = ts.plot()\n",
    "start,end = '1960-01-01','1962-01-01'\n",
    "modelo_treinado.plot_predict(start,end,ax=eixo,plot_insample=True) #plota e faz predição (inicio, fim /da previsao, junta os graficos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
